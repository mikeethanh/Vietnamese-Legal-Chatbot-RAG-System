# HÆ°á»›ng dáº«n Import Dá»¯ liá»‡u Finetune vÃ o Qdrant

Script nÃ y giÃºp báº¡n import dá»¯ liá»‡u tá»« file `combined_finetune_data.jsonl` vÃ o Qdrant vector database Ä‘á»ƒ phá»¥c vá»¥ cho há»‡ thá»‘ng RAG.

## ğŸ“Š Cáº¥u trÃºc dá»¯ liá»‡u

File JSONL cÃ³ cáº¥u trÃºc nhÆ° sau:
```json
{"question": "Ban cháº¥p hÃ nh Há»™i ngÆ°á»i cao tuá»•i Viá»‡t Nam lÃ  cÆ¡ quan nhÆ° tháº¿ nÃ o theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t?", "context": "Ban Cháº¥p hÃ nh Há»™i\n1. Ban Cháº¥p hÃ nh Há»™i NgÆ°á»i cao tuá»•i Viá»‡t Nam do Äáº¡i há»™i hiá»‡p thÆ°Æ¡ng dÃ¢n chá»§ báº§u ra...", "source": "valid", "id": "valid_17916"}
```

Script sáº½:
- Láº¥y trÆ°á»ng `question` lÃ m **title**
- Láº¥y trÆ°á»ng `context` lÃ m **content**  
- Sá»­ dá»¥ng `id` lÃ m document ID trong Qdrant
- Bá» qua cÃ¡c trÆ°á»ng khÃ¡c (`source`, ...)

---

## ğŸ³ CÃ¡ch 1: Sá»­ dá»¥ng vá»›i Docker (KhuyÃªn dÃ¹ng)

### Äiá»u kiá»‡n tiÃªn quyáº¿t

```bash
# Äáº£m báº£o cÃ¡c containers Ä‘ang cháº¡y
cd backend
docker-compose up -d

# Kiá»ƒm tra
docker ps | grep chatbot
docker ps | grep qdrant
```

### Quick Start

```bash
# Di chuyá»ƒn vÃ o thÆ° má»¥c backend
cd backend

# Import toÃ n bá»™ dá»¯ liá»‡u
./import_data.sh

# Hoáº·c test vá»›i 1000 records Ä‘áº§u tiÃªn
./import_data.sh --max-records 1000

# Import theo batch
./import_data.sh --start-from 0 --max-records 50000
./import_data.sh --start-from 50000 --max-records 50000
```

### CÃ¡c tham sá»‘ cá»§a import_data.sh

```bash
./import_data.sh [options]

Options:
  --file <path>          ÄÆ°á»ng dáº«n file JSONL trong container
                         (máº·c Ä‘á»‹nh: ../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl)
  --collection <name>    TÃªn collection Qdrant (máº·c Ä‘á»‹nh: legal_knowledge)
  --batch-size <num>     KÃ­ch thÆ°á»›c batch (máº·c Ä‘á»‹nh: 100)
  --start-from <num>     Báº¯t Ä‘áº§u tá»« record thá»© N (máº·c Ä‘á»‹nh: 0)
  --max-records <num>    Sá»‘ records tá»‘i Ä‘a (máº·c Ä‘á»‹nh: táº¥t cáº£)
  --help                 Hiá»ƒn thá»‹ trá»£ giÃºp
```

### VÃ­ dá»¥ thá»±c táº¿ vá»›i Docker

```bash
# Test vá»›i 100 records trÆ°á»›c khi import háº¿t
./import_data.sh --max-records 100 --collection test_collection

# Import batch 50k records Ä‘áº§u tiÃªn
./import_data.sh --start-from 0 --max-records 50000

# Import batch tiáº¿p theo
./import_data.sh --start-from 50000 --max-records 50000

# Import vá»›i collection name khÃ¡c
./import_data.sh --collection legal_finetune_data --max-records 10000
```

### Cháº¡y import trong ná»n (background)

```bash
# Cháº¡y import trong background vá»›i nohup
nohup ./import_data.sh --max-records 100000 > import.log 2>&1 &

# Xem progress
tail -f import.log

# Hoáº·c dÃ¹ng docker logs
docker logs -f chatbot-worker
```

### CÃ¡ch thay tháº¿: Cháº¡y trá»±c tiáº¿p docker exec

```bash
# VÃ o container
docker exec -it chatbot-worker bash

# Trong container, cháº¡y:
cd /usr/src/app/src
python import_finetune_data.py \
  --file /usr/src/app/../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl \
  --max-records 1000

# Exit container
exit
```

---

## ğŸ’» CÃ¡ch 2: Cháº¡y trá»±c tiáº¿p (KhÃ´ng dÃ¹ng Docker)

Náº¿u báº¡n **KHÃ”NG** dÃ¹ng Docker vÃ  cháº¡y Python trá»±c tiáº¿p trÃªn mÃ¡y:

### CÃ i Ä‘áº·t

```bash
# CÃ i dependencies
cd backend
pip install -r requirements.txt

# Optional: CÃ i tqdm Ä‘á»ƒ cÃ³ progress bar Ä‘áº¹p hÆ¡n
pip install tqdm
```

### Äáº£m báº£o services Ä‘ang cháº¡y

```bash
# Qdrant pháº£i Ä‘ang cháº¡y (port 6333)
# Redis/Valkey pháº£i Ä‘ang cháº¡y (port 6379)

# Náº¿u dÃ¹ng Docker cho database:
cd database
docker-compose up -d

cd ../backend
docker-compose up -d qdrant-db valkey-db
```

### Cháº¡y script

```bash
cd backend/src

# Import toÃ n bá»™
python import_finetune_data.py \
  --file ../../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl

# Import vá»›i collection cá»¥ thá»ƒ
python import_finetune_data.py \
  --file ../../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl \
  --collection legal_finetune_data

# Test vá»›i 1000 records
python import_finetune_data.py \
  --file ../../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl \
  --max-records 1000

# Import theo batch
python import_finetune_data.py \
  --file ../../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl \
  --start-from 0 \
  --max-records 50000
```

---

## ğŸ“ CÃ¡c tham sá»‘ chi tiáº¿t

| Tham sá»‘ | MÃ´ táº£ | Máº·c Ä‘á»‹nh | Báº¯t buá»™c |
|---------|-------|----------|----------|
| `--file` | ÄÆ°á»ng dáº«n Ä‘áº¿n file JSONL | - | âœ… |
| `--collection` | TÃªn collection trong Qdrant | `legal_knowledge` | âŒ |
| `--batch-size` | Sá»‘ records xá»­ lÃ½ trÆ°á»›c khi nghá»‰ | 100 | âŒ |
| `--start-from` | Bá» qua N records Ä‘áº§u tiÃªn | 0 | âŒ |
| `--max-records` | Sá»‘ records tá»‘i Ä‘a muá»‘n import | Táº¥t cáº£ | âŒ |

---

## âš ï¸ LÆ°u Ã½ quan trá»ng

### 1. Thá»i gian xá»­ lÃ½
Vá»›i **608,689 records**:
- Má»—i record cáº§n ~0.1-0.5 giÃ¢y (tÃ¹y thuá»™c embedding model vÃ  tá»‘c Ä‘á»™)
- **Æ¯á»›c tÃ­nh: 17-84 giá»** Ä‘á»ƒ import toÃ n bá»™
- **Khuyáº¿n nghá»‹**: 
  - Test vá»›i 100-1000 records trÆ°á»›c
  - Chia batch 50k-100k records
  - Cháº¡y qua Ä‘Ãªm hoáº·c trong background

### 2. Chiáº¿n lÆ°á»£c import cho dá»¯ liá»‡u lá»›n

#### Chiáº¿n lÆ°á»£c A: Import tá»«ng batch tuáº§n tá»±
```bash
# Batch 1: Records 0-100000
./import_data.sh --start-from 0 --max-records 100000

# Batch 2: Records 100000-200000  
./import_data.sh --start-from 100000 --max-records 100000

# Batch 3: Records 200000-300000
./import_data.sh --start-from 200000 --max-records 100000

# ... tiáº¿p tá»¥c
```

#### Chiáº¿n lÆ°á»£c B: Script tá»± Ä‘á»™ng chia batch
```bash
# Táº¡o script tá»± Ä‘á»™ng
cat > auto_import.sh << 'EOF'
#!/bin/bash
TOTAL_RECORDS=608689
BATCH_SIZE=50000
START=0

while [ $START -lt $TOTAL_RECORDS ]; do
  echo "Importing batch starting at $START..."
  ./import_data.sh --start-from $START --max-records $BATCH_SIZE
  START=$((START + BATCH_SIZE))
  echo "Sleeping 10 seconds before next batch..."
  sleep 10
done
EOF

chmod +x auto_import.sh
./auto_import.sh
```

### 3. Monitoring

#### Xem logs realtime (Docker)
```bash
# Theo dÃµi logs cá»§a worker
docker logs -f chatbot-worker

# Hoáº·c náº¿u cháº¡y qua import_data.sh
tail -f import.log
```

#### Kiá»ƒm tra sá»‘ lÆ°á»£ng trong Qdrant
```python
from qdrant_client import QdrantClient

client = QdrantClient(url="http://localhost:6333")
collection_info = client.get_collection("legal_knowledge")
print(f"Total points: {collection_info.points_count}")
```

### 4. Recovery khi bá»‹ giÃ¡n Ä‘oáº¡n

Náº¿u script dá»«ng giá»¯a chá»«ng:
1. Kiá»ƒm tra log Ä‘á»ƒ xem Ä‘Ã£ import Ä‘áº¿n record nÃ o
2. Sá»­ dá»¥ng `--start-from` Ä‘á»ƒ tiáº¿p tá»¥c

```bash
# VÃ­ dá»¥: Script dá»«ng á»Ÿ record 50000
./import_data.sh --start-from 50000
```

### 5. Tá»‘i Æ°u hiá»‡u nÄƒng

#### Trong Docker
- TÄƒng resources cho container trong `docker-compose.yml`:
```yaml
chatbot-worker:
  # ... existing config
  deploy:
    resources:
      limits:
        cpus: '4'
        memory: 4G
```

#### TÄƒng tá»‘c embedding
- Náº¿u dÃ¹ng local embedding model â†’ Sá»­ dá»¥ng GPU
- Náº¿u dÃ¹ng API embedding (OpenAI, Cohere) â†’ TÄƒng rate limit

---

## ğŸ§ª Testing & Validation

### Test trÆ°á»›c khi import háº¿t

```bash
# Test vá»›i 100 records vÃ o collection test
./import_data.sh --max-records 100 --collection test_legal

# Kiá»ƒm tra káº¿t quáº£
python << EOF
from vectorize import search_vector
from brain import get_embedding

query = "Quy Ä‘á»‹nh vá» ngÆ°á»i cao tuá»•i"
vector = get_embedding(query)
results = search_vector("test_legal", vector, limit=5)
print("Test results:")
for i, doc in enumerate(results, 1):
    print(f"{i}. {doc.get('title', 'N/A')[:100]}...")
EOF
```

### Validate sau khi import

```bash
# VÃ o container Python
docker exec -it chatbot-worker python

# Trong Python shell:
from vectorize import search_vector
from brain import get_embedding
from qdrant_client import QdrantClient

# Kiá»ƒm tra sá»‘ lÆ°á»£ng
client = QdrantClient(url="http://qdrant-db:6333")
info = client.get_collection("legal_knowledge")
print(f"Total documents: {info.points_count}")

# Test search
query = "Thá»«a káº¿ tÃ i sáº£n"
vector = get_embedding(query)
results = search_vector("legal_knowledge", vector, limit=3)

for i, doc in enumerate(results, 1):
    print(f"\n--- Result {i} ---")
    print(f"Title: {doc.get('title', 'N/A')}")
    print(f"Content preview: {doc.get('content', 'N/A')[:200]}...")
```

---

## ğŸ“Š Output máº«u

### Khi cháº¡y vá»›i Docker

```
Checking Docker containers...
âœ“ All containers are running

Import Configuration:
  Container: chatbot-worker
  File: /usr/src/app/../data_pipeline/data/process_data/finetune_data/combined_finetune_data.jsonl
  Collection: legal_knowledge
  Batch size: 100
  Start from: 0
  Max records: 1000

Continue? (y/n) y
Starting import...

2025-10-27 10:00:00 - INFO - Starting import process...
2025-10-27 10:00:00 - INFO - Counting total records...
2025-10-27 10:00:05 - INFO - Total records in file: 608689
2025-10-27 10:00:05 - INFO - Starting import from record 0, will process 1000 records
Importing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [05:23<00:00, success=998, errors=0, skipped=2]
============================================================
Import Summary:
  Total processed: 1000
  Successfully imported: 998
  Errors: 0
  Skipped (missing data): 2
============================================================

âœ“ Import completed!
```

---

## ğŸ”§ Troubleshooting

### Lá»—i: "chatbot-worker container is not running"
```bash
cd backend
docker-compose up -d
```

### Lá»—i: "qdrant-db container is not running"
```bash
cd database
docker-compose up -d
# hoáº·c
cd backend
docker-compose up -d qdrant-db
```

### Lá»—i: "Collection already exists"
âœ… KhÃ´ng sao, script sáº½ tá»± Ä‘á»™ng sá»­ dá»¥ng collection hiá»‡n cÃ³.

### Lá»—i: "Connection refused to Qdrant"
Kiá»ƒm tra Qdrant cÃ³ Ä‘ang cháº¡y khÃ´ng:
```bash
curl http://localhost:6333/collections
# Hoáº·c tá»« trong container:
docker exec chatbot-worker curl http://qdrant-db:6333/collections
```

### Lá»—i: "No embedding model configured"
Kiá»ƒm tra file `.env` trong `backend/`:
```bash
# Cáº§n cÃ³ cÃ¡c biáº¿n nÃ y
OPENAI_API_KEY=your_key
# Hoáº·c
EMBEDDING_API_URL=your_custom_embedding_url
```

### Script cháº¡y quÃ¡ cháº­m
- Kiá»ƒm tra embedding model (local vs API)
- TÄƒng resources cho Docker
- Giáº£m `--batch-size` hoáº·c chia nhá» hÆ¡n

---

## âœ… Káº¿t quáº£ sau khi import thÃ nh cÃ´ng

Dá»¯ liá»‡u sáº½ cÃ³ trong Qdrant vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho:

1. âœ… **RAG queries** - Tráº£ lá»i cÃ¢u há»i phÃ¡p luáº­t qua `bot_rag_answer_message()`
2. âœ… **Vector search** - TÃ¬m kiáº¿m ngá»¯ nghÄ©a qua `search_vector()`
3. âœ… **Multi-query retrieval** - TÃ¬m kiáº¿m vá»›i nhiá»u query variations
4. âœ… **Reranking** - Sáº¯p xáº¿p láº¡i káº¿t quáº£ theo Ä‘á»™ liÃªn quan
5. âœ… **Conversational AI** - Chat vá»›i context tá»« corpus phÃ¡p luáº­t

---

**Ghi chÃº**: Script nÃ y sá»­ dá»¥ng hÃ m `index_document_v2()` cÃ³ sáºµn trong há»‡ thá»‘ng, Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n vá»›i RAG pipeline Ä‘ang cháº¡y. Má»—i document sáº½ Ä‘Æ°á»£c:
1. Split thÃ nh cÃ¡c chunks nhá» hÆ¡n (náº¿u quÃ¡ dÃ i)
2. Embedding báº±ng model hiá»‡n táº¡i
3. LÆ°u vÃ o Qdrant vá»›i metadata (title, content)
