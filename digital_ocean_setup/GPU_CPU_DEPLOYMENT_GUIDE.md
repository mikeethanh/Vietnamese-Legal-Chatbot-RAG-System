# ðŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng GPU Droplet cho Training + CPU Droplet cho Serving

## ðŸŽ¯ Chiáº¿n lÆ°á»£c

**Training**: GPU Droplet (táº¡m thá»i, xÃ³a sau khi train xong) â†’ Tiáº¿t kiá»‡m chi phÃ­
**Serving**: CPU Droplet (cháº¡y lÃ¢u dÃ i) â†’ á»”n Ä‘á»‹nh vÃ  ráº»

## BÆ°á»›c 1: Táº¡o GPU Droplet cho Training

### 1.1. VÃ o Digital Ocean Dashboard
1. Login: https://cloud.digitalocean.com/
2. Click **"Create"** â†’ **"Droplets"**

### 1.2. Cáº¥u hÃ¬nh GPU Droplet
1. **Operating System**: Ubuntu 22.04 (LTS) x64
2. **Plan**: Click tab **"Premium Intel with GPU"**
3. **GPU Options**:
   - **Basic GPU**: $72/month - 1 vCPU, 8GB RAM, 1 GPU (NVIDIA V100) â† Khuyáº¿n nghá»‹
   - **Professional GPU**: $144/month - 2 vCPUs, 16GB RAM, 1 GPU (NVIDIA V100) â† Náº¿u cáº§n performance cao
4. **Datacenter**: Singapore (SGP1)
5. **Authentication**: SSH Key (khuyáº¿n nghá»‹)
6. **Hostname**: `legal-ai-gpu-training`
7. **Tags**: `gpu`, `training`, `temporary`
8. Click **"Create Droplet"**

### 1.3. Ghi láº¡i thÃ´ng tin
- **GPU Droplet IP**: `_______________`

---

## BÆ°á»›c 2: Táº¡o CPU Droplet cho Serving

### 2.1. Táº¡o CPU Droplet thá»© 2
1. Click **"Create"** â†’ **"Droplets"** (láº§n 2)
2. **Operating System**: Ubuntu 22.04 (LTS) x64
3. **Plan**: Basic - Regular with SSD
4. **Size**: 
   - **$24/month**: 4GB RAM, 2 vCPUs, 80GB SSD â† Cho serving cÆ¡ báº£n
   - **$48/month**: 8GB RAM, 4 vCPUs, 160GB SSD â† Khuyáº¿n nghá»‹ cho performance tá»‘t
5. **Datacenter**: Singapore (SGP1) (cÃ¹ng region)
6. **Authentication**: SSH Key (dÃ¹ng cÃ¹ng key)
7. **Hostname**: `legal-ai-cpu-serving`
8. **Tags**: `cpu`, `serving`, `production`
9. Click **"Create Droplet"**

### 2.2. Ghi láº¡i thÃ´ng tin
- **CPU Droplet IP**: `_______________`

---

## BÆ°á»›c 3: Setup GPU Droplet cho Training

### 3.1. Káº¿t ná»‘i GPU Droplet
```bash
ssh root@GPU_DROPLET_IP
```

### 3.2. CÃ i Ä‘áº·t NVIDIA Drivers vÃ  CUDA
```bash
# Update system
apt update && apt upgrade -y

# Install NVIDIA drivers
apt install -y ubuntu-drivers-common
ubuntu-drivers autoinstall

# Reboot Ä‘á»ƒ load drivers
reboot
```

**Äá»£i 2-3 phÃºt vÃ  káº¿t ná»‘i láº¡i:**
```bash
ssh root@GPU_DROPLET_IP
```

### 3.3. Verify GPU
```bash
# Check GPU
nvidia-smi
```

**Káº¿t quáº£ mong muá»‘n:**
```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.xx.xx              Driver Version: 580.xx.xx      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          Off |   00000000:00:09.0 Off |                    0 |
| N/A   29C    P0             68W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
```

ðŸŽ‰ **TUYá»†T Vá»œI! Báº¡n cÃ³ GPU H100 - Top tier GPU hiá»‡n táº¡i!**
- **Memory**: 80GB (vs 16GB V100) â†’ CÃ³ thá»ƒ train batch size cá»±c lá»›n
- **Performance**: 3-4x nhanh hÆ¡n V100
- **CUDA**: 13.0 (latest) â†’ Há»— trá»£ táº¥t cáº£ optimization má»›i nháº¥t

### 3.4. CÃ i Ä‘áº·t Docker vá»›i GPU support
```bash
# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
&& curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add - \
&& curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list

apt update && apt install -y nvidia-docker2
systemctl restart docker

# Test GPU in Docker
docker run --rm --gpus all nvidia/cuda:13.0.1-base-ubuntu22.04 nvidia-smi
```

---

## BÆ°á»›c 4: Setup Repository trÃªn GPU Droplet

### 4.1. Clone repository
```bash
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 4.2. Cáº¥u hÃ¬nh environment
```bash
cp .env.template .env
nano .env
```

**Cáº­p nháº­t file .env (thay YOUR_ACTUAL_KEYS báº±ng keys tháº­t):**
```bash
# Digital Ocean Spaces Configuration
SPACES_ACCESS_KEY=YOUR_ACTUAL_SPACES_ACCESS_KEY
SPACES_SECRET_KEY=YOUR_ACTUAL_SPACES_SECRET_KEY
SPACES_ENDPOINT=https://sgp1.digitaloceanspaces.com
SPACES_BUCKET=legal-datalake

# VietAI ELECTRA Model Configuration
BASE_MODEL=VietAI/viet-electra-base
MODEL_PATH=models/embedding_model_latest

# H100 GPU Optimized Training Parameters
EPOCHS=8
GPU_BATCH_SIZE=128
LEARNING_RATE=1e-5
WARMUP_STEPS=1000
MAX_SEQ_LENGTH=512
GRADIENT_ACCUMULATION_STEPS=4
USE_FP16=true

# GPU Configuration
USE_GPU=true
CUDA_VISIBLE_DEVICES=0

# General Parameters
MAX_SAMPLES=50000
```

### 4.3. Táº¡o thÆ° má»¥c cáº§n thiáº¿t
```bash
mkdir -p data models logs
```

---

## BÆ°á»›c 5: Setup GPU Training Environment

### 5.1. Kiá»ƒm tra file training script
```bash
# Kiá»ƒm tra file training script cÃ³ tá»“n táº¡i
ls -la train_embedding_gpu.py
```

**Náº¿u file khÃ´ng tá»“n táº¡i, download tá»« repository:**
```bash
# Äáº£m báº£o cÃ³ file training script
if [ ! -f "train_embedding_gpu.py" ]; then
    echo "âŒ File train_embedding_gpu.py khÃ´ng tÃ¬m tháº¥y!"
    echo "ðŸ“¥ Vui lÃ²ng Ä‘áº£m báº£o repository Ä‘Æ°á»£c clone Ä‘áº§y Ä‘á»§"
    exit 1
fi
```

### 5.2. Kiá»ƒm tra requirements file
```bash
# Sá»­ dá»¥ng requirements_gpu.txt cho GPU training
ls -la requirements_gpu.txt

# Náº¿u khÃ´ng cÃ³, táº¡o requirements file
cat > requirements_gpu.txt << 'EOF'
# GPU Training Requirements - Optimized for NVIDIA V100/H100
torch>=2.0.1
sentence-transformers>=2.3.0
transformers>=4.30.0
accelerate>=0.20.0
datasets>=2.10.0

# Core ML libraries
numpy>=1.24.0
scikit-learn>=1.3.0
pandas>=2.0.0

# Cloud storage
boto3>=1.26.0
botocore>=1.29.0

# Monitoring and logging
psutil>=5.9.0

# Utilities
tqdm>=4.65.0
requests>=2.31.0
EOF
```

### 5.3. Build GPU Docker Image (cáº­p nháº­t vá»›i CUDA 12.2)
```bash
# Táº¡o Dockerfile.gpu-training vá»›i CUDA version má»›i nháº¥t
cat > Dockerfile.gpu-training << 'EOF'
# GPU Training Dockerfile - Updated for latest CUDA
FROM nvidia/cuda:13.0.1-base-ubuntu22.04 

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    python3.10-dev \
    git \
    curl \
    wget \
    build-essential \
    software-properties-common \
    && rm -rf /var/lib/apt/lists/*

# Create symbolic links
RUN ln -sf /usr/bin/python3.10 /usr/bin/python
RUN ln -sf /usr/bin/pip3 /usr/bin/pip

# Upgrade pip
RUN python -m pip install --upgrade pip

# Copy requirements vÃ  install Python dependencies
COPY requirements_gpu.txt requirements.txt
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
RUN pip install --no-cache-dir -r requirements.txt

# Copy training script
COPY train_embedding_gpu.py .
COPY .env .env

# Create directories
RUN mkdir -p /tmp/data /tmp/model /tmp/logs

# Set environment variables
ENV PYTHONPATH=/app
ENV TOKENIZERS_PARALLELISM=false
ENV CUDA_VISIBLE_DEVICES=0
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Default command
CMD ["python", "train_embedding_gpu.py"]
EOF
```

---

## BÆ°á»›c 6: Training trÃªn GPU Droplet

### 6.1. Load environment variables
```bash
# Load environment variables
source .env

# Verify environment variables
echo "ðŸ” Checking environment variables..."
echo "SPACES_ACCESS_KEY: ${SPACES_ACCESS_KEY:0:10}..." 
echo "SPACES_SECRET_KEY: ${SPACES_SECRET_KEY:0:10}..."
echo "SPACES_BUCKET: $SPACES_BUCKET"
echo "BASE_MODEL: $BASE_MODEL"
```

### 6.2. Build GPU image
```bash
# Build vá»›i verbose output Ä‘á»ƒ debug
docker build -f Dockerfile.gpu-training -t legal-embedding-gpu:latest . --no-cache

# Kiá»ƒm tra image Ä‘Ã£ build thÃ nh cÃ´ng
docker images | grep legal-embedding-gpu
```

### 6.3. Test GPU access trong Docker
```bash
# Test GPU trÆ°á»›c khi training
docker run --rm --gpus all legal-embedding-gpu:latest nvidia-smi

# Test PyTorch GPU access
docker run --rm --gpus all legal-embedding-gpu:latest python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA devices: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'Device name: {torch.cuda.get_device_name(0)}')
"
```

### 6.4. Run training vá»›i GPU (method 1: Direct run)
```bash
# Äáº£m báº£o Ä‘ang á»Ÿ Ä‘Ãºng thÆ° má»¥c
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Load environment variables
source .env

# Run training vá»›i full config tá»« .env
docker run --gpus all \
  --name legal-gpu-training \
  -v $(pwd)/data:/tmp/data \
  -v $(pwd)/models:/tmp/model \
  -v $(pwd)/logs:/tmp/logs \
  -v $(pwd)/.env:/app/.env:ro \
  -e SPACES_ACCESS_KEY="$SPACES_ACCESS_KEY" \
  -e SPACES_SECRET_KEY="$SPACES_SECRET_KEY" \
  -e SPACES_ENDPOINT="$SPACES_ENDPOINT" \
  -e SPACES_BUCKET="$SPACES_BUCKET" \
  -e BASE_MODEL="$BASE_MODEL" \
  -e MODEL_PATH="$MODEL_PATH" \
  -e EPOCHS="$EPOCHS" \
  -e GPU_BATCH_SIZE="$GPU_BATCH_SIZE" \
  -e LEARNING_RATE="$LEARNING_RATE" \
  -e WARMUP_STEPS="$WARMUP_STEPS" \
  -e MAX_SEQ_LENGTH="$MAX_SEQ_LENGTH" \
  -e GRADIENT_ACCUMULATION_STEPS="$GRADIENT_ACCUMULATION_STEPS" \
  -e USE_FP16="$USE_FP16" \
  -e USE_GPU="$USE_GPU" \
  -e CUDA_VISIBLE_DEVICES="$CUDA_VISIBLE_DEVICES" \
  -e MAX_SAMPLES="$MAX_SAMPLES" \
  --rm \
  legal-embedding-gpu:latest
```

### 6.5. Alternative: Run vá»›i script automation
```bash
# Sá»­ dá»¥ng automation script
./gpu_cpu_deploy.sh gpu-train

# Hoáº·c auto-train cho toÃ n bá»™ workflow
./gpu_cpu_deploy.sh auto-train
```

### 6.6. Monitor training (trong terminal khÃ¡c)
```bash
# Terminal 1: Monitor GPU usage
watch -n 5 nvidia-smi

# Terminal 2: Monitor Docker logs
docker logs -f legal-gpu-training

# Terminal 3: Monitor system resources
watch -n 10 'echo "=== CPU/Memory ===" && top -n 1 | head -5 && echo "=== Disk ===" && df -h'
```

### 6.7. Training progress tracking
```bash
# Kiá»ƒm tra training progress
ls -la models/
tail -f logs/training.log

# Kiá»ƒm tra model Ä‘Ã£ upload lÃªn Spaces
# (Náº¿u training script cÃ³ auto-upload)
```

**â° Thá»i gian training:**
- **GPU V100**: 15-30 phÃºt
- **GPU H100**: 8-15 phÃºt  
- **Batch size**: CÃ³ thá»ƒ tÄƒng lÃªn 128+ vá»›i GPU H100

**ðŸš¨ Troubleshooting:**
```bash
# Náº¿u training fail, check logs
docker logs legal-gpu-training

# Kiá»ƒm tra GPU memory
nvidia-smi

# Restart náº¿u cáº§n
docker stop legal-gpu-training
docker rm legal-gpu-training
# Rá»“i cháº¡y láº¡i command á»Ÿ bÆ°á»›c 6.4
```

---

## BÆ°á»›c 7: Setup CPU Droplet cho Serving

### 7.1. Káº¿t ná»‘i CPU Droplet
```bash
ssh root@CPU_DROPLET_IP
```

### 7.2. Setup CPU Droplet
```bash
# Update system
apt update && apt upgrade -y

# Install dependencies
apt install -y git curl wget build-essential

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install Docker Compose
curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

# Clone repository
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 7.3. Cáº¥u hÃ¬nh environment
```bash
cp .env.template .env
nano .env
```

**Cáº­p nháº­t .env cho CPU serving:**
```bash
# Digital Ocean Spaces Configuration
SPACES_ACCESS_KEY=your_spaces_access_key_here
SPACES_SECRET_KEY=your_spaces_secret_key_here
SPACES_ENDPOINT=https://sf03.digitaloceanspaces.com
SPACES_BUCKET=legal-datalake

# CPU Serving specific
USE_GPU=false
MODEL_PATH=models/embedding_model_YYYYMMDD_HHMMSS  # Tá»« GPU training
PORT=5000
BATCH_SIZE=16  # Tháº¥p hÆ¡n cho CPU
```

---

## BÆ°á»›c 8: Transfer Model tá»« GPU sang CPU Droplet

### 8.1. Sau khi training xong trÃªn GPU

**TrÃªn GPU Droplet:**
```bash
# Kiá»ƒm tra model Ä‘Ã£ upload lÃªn Spaces
ls -la /tmp/model/
# Ghi láº¡i model path trÃªn Spaces
```

### 8.2. Download model trÃªn CPU Droplet

**TrÃªn CPU Droplet:**
```bash
# Build serving image
docker-compose build embedding-server

# Deploy serving services
./deploy.sh deploy
```

---

## BÆ°á»›c 9: Verify vÃ  Test

### 9.1. Test CPU Serving Droplet
```bash
# TrÃªn CPU Droplet
./deploy.sh health

# Test tá»« local
curl http://CPU_DROPLET_IP/health
```

### 9.2. Performance comparison
```bash
# Test embedding speed
python test_api.py http://CPU_DROPLET_IP:5000
```

---

## BÆ°á»›c 10: Cleanup GPU Droplet

### 10.1. Backup quan trá»ng
**TrÃªn GPU Droplet:**
```bash
# Backup logs vÃ  configs
tar -czf training_backup.tar.gz /tmp/model /tmp/data /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup/.env

# Upload backup lÃªn Spaces (optional)
aws s3 cp training_backup.tar.gz s3://legal-datalake/backups/ --endpoint-url=https://sgp1.digitaloceanspaces.com
```

### 10.2. Destroy GPU Droplet
1. **VÃ o Digital Ocean Dashboard**
2. **Droplets** â†’ **legal-ai-gpu-training**
3. **Settings** â†’ **Destroy**
4. **Type droplet name** â†’ **Destroy**

ðŸ’° **Tiáº¿t kiá»‡m**: Thay vÃ¬ $72/month GPU liÃªn tá»¥c â†’ chá»‰ tráº£ $1-2 cho vÃ i giá» training

---

## ðŸ“Š So sÃ¡nh Performance & Cost

### Training Performance
| PhÆ°Æ¡ng Ã¡n | Thá»i gian | Chi phÃ­/training | GPU Memory |
|-----------|-----------|------------------|------------|
| CPU Droplet | 60-90 phÃºt | ~$0.50 | 0 GB |
| GPU Droplet | 15-30 phÃºt | ~$1-2 | 16 GB |

### Serving Performance  
| PhÆ°Æ¡ng Ã¡n | Response time | Chi phÃ­/thÃ¡ng | Throughput |
|-----------|---------------|---------------|------------|
| CPU Droplet | 200-500ms | $24-48 | 5-10 req/s |
| GPU Droplet | 50-100ms | $72+ | 20-50 req/s |

### Khuyáº¿n nghá»‹ tá»‘i Æ°u
- **Training**: GPU Droplet (destroy sau khi dÃ¹ng)
- **Serving**: CPU Droplet (cháº¡y lÃ¢u dÃ i)
- **Re-training**: Táº¡o GPU Droplet má»›i khi cáº§n

---

## ðŸ”„ Workflow tá»‘i Æ°u

1. **Monthly/Quarterly**: Táº¡o GPU Droplet â†’ Train model má»›i â†’ Destroy
2. **Daily**: CPU Droplet serving 24/7
3. **Update**: Download model má»›i tá»« Spaces â†’ Restart serving

**ðŸ’¡ Lá»£i Ã­ch**: 
- Tiáº¿t kiá»‡m 70-80% chi phÃ­
- Training nhanh hÆ¡n 3-4 láº§n
- Serving á»•n Ä‘á»‹nh vÃ  ráº»