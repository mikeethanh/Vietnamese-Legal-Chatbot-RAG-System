# üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng GPU Droplet cho Training + CPU Droplet cho Serving

## üéØ Chi·∫øn l∆∞·ª£c

**Training**: GPU Droplet (t·∫°m th·ªùi, x√≥a sau khi train xong) ‚Üí Ti·∫øt ki·ªám chi ph√≠
**Serving**: CPU Droplet (ch·∫°y l√¢u d√†i) ‚Üí ·ªîn ƒë·ªãnh v√† r·∫ª

## B∆∞·ªõc 1: T·∫°o GPU Droplet cho Training

### 1.1. V√†o Digital Ocean Dashboard
1. Login: https://cloud.digitalocean.com/
2. Click **"Create"** ‚Üí **"Droplets"**

### 1.2. C·∫•u h√¨nh GPU Droplet
1. **Operating System**: Ubuntu 22.04 (LTS) x64
2. **Plan**: Click tab **"Premium Intel with GPU"**
3. **GPU Options**:
   - **Basic GPU**: $72/month - 1 vCPU, 8GB RAM, 1 GPU (NVIDIA V100) ‚Üê Khuy·∫øn ngh·ªã
   - **Professional GPU**: $144/month - 2 vCPUs, 16GB RAM, 1 GPU (NVIDIA V100) ‚Üê N·∫øu c·∫ßn performance cao
4. **Datacenter**: Singapore (SGP1)
5. **Authentication**: SSH Key (khuy·∫øn ngh·ªã)
6. **Hostname**: `legal-ai-gpu-training`
7. **Tags**: `gpu`, `training`, `temporary`
8. Click **"Create Droplet"**

### 1.3. Ghi l·∫°i th√¥ng tin
- **GPU Droplet IP**: `_______________`

---

## B∆∞·ªõc 2: T·∫°o CPU Droplet cho Serving

### 2.1. T·∫°o CPU Droplet th·ª© 2
1. Click **"Create"** ‚Üí **"Droplets"** (l·∫ßn 2)
2. **Operating System**: Ubuntu 22.04 (LTS) x64
3. **Plan**: Basic - Regular with SSD
4. **Size**: 
   - **$24/month**: 4GB RAM, 2 vCPUs, 80GB SSD ‚Üê Cho serving c∆° b·∫£n
   - **$48/month**: 8GB RAM, 4 vCPUs, 160GB SSD ‚Üê Khuy·∫øn ngh·ªã cho performance t·ªët
5. **Datacenter**: Singapore (SGP1) (c√πng region)
6. **Authentication**: SSH Key (d√πng c√πng key)
7. **Hostname**: `legal-ai-cpu-serving`
8. **Tags**: `cpu`, `serving`, `production`
9. Click **"Create Droplet"**

### 2.2. Ghi l·∫°i th√¥ng tin
- **CPU Droplet IP**: `_______________`

---

## B∆∞·ªõc 3: Setup GPU Droplet cho Training

### 3.1. K·∫øt n·ªëi GPU Droplet
```bash
ssh root@GPU_DROPLET_IP
```

### 3.2. C√†i ƒë·∫∑t NVIDIA Drivers v√† CUDA
```bash
# Update system
apt update && apt upgrade -y

# Install NVIDIA drivers
apt install -y ubuntu-drivers-common
ubuntu-drivers autoinstall

# Reboot ƒë·ªÉ load drivers
reboot
```

**ƒê·ª£i 2-3 ph√∫t v√† k·∫øt n·ªëi l·∫°i:**
```bash
ssh root@GPU_DROPLET_IP
```

### 3.3. Verify GPU
```bash
# Check GPU
nvidia-smi
```

### 3.4. C√†i ƒë·∫∑t Docker v·ªõi GPU support
```bash
# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
&& curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add - \
&& curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list

apt update && apt install -y nvidia-docker2
systemctl restart docker

# Test GPU in Docker
docker run --rm --gpus all nvidia/cuda:13.0.1-base-ubuntu22.04 nvidia-smi
```

---

## B∆∞·ªõc 4: Setup Repository tr√™n GPU Droplet

### 4.1. Clone repository
```bash
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 4.2. C·∫•u h√¨nh environment
```bash
cp .env.template .env
nano .env
```

### 4.3. T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
```bash
mkdir -p data models logs
```

---

## B∆∞·ªõc 5: Setup GPU Training Environment

### 5.1. Ki·ªÉm tra file training script
```bash
# Ki·ªÉm tra file training script c√≥ t·ªìn t·∫°i
ls -la train_embedding_gpu.py
```

### 5.2. Ki·ªÉm tra requirements file
```bash
# S·ª≠ d·ª•ng requirements_gpu.txt cho GPU training
ls -la requirements_gpu.txt
```
## B∆∞·ªõc 6: Training tr√™n GPU Droplet

### 6.1. Load environment variables
```bash
# Load environment variables
source .env

# Verify environment variables
echo "üîç Checking environment variables..."
echo "SPACES_ACCESS_KEY: ${SPACES_ACCESS_KEY:0:10}..." 
echo "SPACES_SECRET_KEY: ${SPACES_SECRET_KEY:0:10}..."
echo "SPACES_BUCKET: $SPACES_BUCKET"
echo "BASE_MODEL: $BASE_MODEL"
```

### 6.2. Build GPU image
```bash
# Build v·ªõi verbose output ƒë·ªÉ debug
docker build -f Dockerfile.gpu-training -t legal-embedding-gpu:latest . --no-cache

# Ki·ªÉm tra image ƒë√£ build th√†nh c√¥ng
docker images | grep legal-embedding-gpu
```

### 6.3. Test GPU access trong Docker
```bash
# Test GPU tr∆∞·ªõc khi training
docker run --rm --gpus all legal-embedding-gpu:latest nvidia-smi

# Test PyTorch GPU access
docker run --rm --gpus all legal-embedding-gpu:latest python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA devices: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'Device name: {torch.cuda.get_device_name(0)}')
"
```

### 6.4. Run training v·ªõi GPU (method 1: Direct run)
```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Load environment variables
source .env

# Run training v·ªõi full config t·ª´ .env
docker run --gpus all \
  --name legal-gpu-training \
  -v $(pwd)/data:/tmp/data \
  -v $(pwd)/models:/tmp/model \
  -v $(pwd)/logs:/tmp/logs \
  -v $(pwd)/.env:/app/.env:ro \
  -e SPACES_ACCESS_KEY="$SPACES_ACCESS_KEY" \
  -e SPACES_SECRET_KEY="$SPACES_SECRET_KEY" \
  -e SPACES_ENDPOINT="$SPACES_ENDPOINT" \
  -e SPACES_BUCKET="$SPACES_BUCKET" \
  -e BASE_MODEL="$BASE_MODEL" \
  -e MODEL_PATH="$MODEL_PATH" \
  -e EPOCHS="$EPOCHS" \
  -e GPU_BATCH_SIZE="$GPU_BATCH_SIZE" \
  -e LEARNING_RATE="$LEARNING_RATE" \
  -e WARMUP_STEPS="$WARMUP_STEPS" \
  -e MAX_SEQ_LENGTH="$MAX_SEQ_LENGTH" \
  -e GRADIENT_ACCUMULATION_STEPS="$GRADIENT_ACCUMULATION_STEPS" \
  -e USE_FP16="$USE_FP16" \
  -e USE_GPU="$USE_GPU" \
  -e CUDA_VISIBLE_DEVICES="$CUDA_VISIBLE_DEVICES" \
  -e MAX_SAMPLES="$MAX_SAMPLES" \
  --rm \
  legal-embedding-gpu:latest
```


### 6.6. Monitor training (trong terminal kh√°c)
```bash
# Terminal 1: Monitor GPU usage
watch -n 5 nvidia-smi

# Terminal 2: Monitor Docker logs
docker logs -f legal-gpu-training

# Terminal 3: Monitor system resources
watch -n 10 'echo "=== CPU/Memory ===" && top -n 1 | head -5 && echo "=== Disk ===" && df -h'
```

### 6.7. Training progress tracking
```bash
# Ki·ªÉm tra training progress
ls -la models/
tail -f logs/training.log

# Ki·ªÉm tra model ƒë√£ upload l√™n Spaces
# (N·∫øu training script c√≥ auto-upload)
```

**üö® Troubleshooting:**
```bash
# N·∫øu training fail, check logs
docker logs legal-gpu-training

# Ki·ªÉm tra GPU memory
nvidia-smi

# Restart n·∫øu c·∫ßn
docker stop legal-gpu-training
docker rm legal-gpu-training
# R·ªìi ch·∫°y l·∫°i command ·ªü b∆∞·ªõc 6.4
```

---

## B∆∞·ªõc 7: Setup CPU Droplet

### 7.1. K·∫øt n·ªëi CPU Droplet
```bash
ssh root@CPU_DROPLET_IP
```

### 7.2. C√†i ƒë·∫∑t Docker
```bash
# Update system
apt update && apt upgrade -y

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Verify Docker installation
docker --version
docker run hello-world
```

### 7.3. Clone repository
```bash
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 7.4. C·∫•u h√¨nh environment cho serving
```bash
# Copy template (n·∫øu c√≥) ho·∫∑c t·∫°o m·ªõi
nano .env.serving
```

**C·∫ßn ƒëi·ªÅn c√°c th√¥ng tin sau trong `.env.serving`:**
```bash
SPACES_ACCESS_KEY=your_access_key_here
SPACES_SECRET_KEY=your_secret_key_here
SPACES_ENDPOINT=https://sgp1.digitaloceanspaces.com
SPACES_BUCKET=legal-datalake

# ƒê·ªÉ tr·ªëng ƒë·ªÉ t·ª± ƒë·ªông l·∫•y model m·ªõi nh·∫•t
MODEL_PATH=

# API config
API_HOST=0.0.0.0
API_PORT=5000
MAX_BATCH_SIZE=32
```

### 7.5. T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
```bash
# T·∫°o th∆∞ m·ª•c models v√† logs
mkdir -p models logs
```

---

## B∆∞·ªõc 8: Build Docker Image v√† Download Model

### 8.1. Build Docker image tr∆∞·ªõc
```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Build image (image n√†y ƒë√£ c√≥ Python v√† t·∫•t c·∫£ dependencies c·∫ßn thi·∫øt)
docker build -f Dockerfile.cpu-serving -t legal-embedding-serving:latest .

# Verify image ƒë√£ build
docker images | grep legal-embedding-serving
```

**üí° L∆∞u √Ω:** Image n√†y ƒë√£ bao g·ªìm:
- Python 3.10
- T·∫•t c·∫£ dependencies trong `requirements_serving.txt`
- Script `download_model_from_spaces.py`
- Script `serve_model.py`

### 8.2. Download model t·ª´ Spaces b·∫±ng Docker container
```bash
# Load environment variables
source .env.serving

# Ch·∫°y container ƒë·ªÉ download model (d√πng image v·ª´a build)
docker run --rm \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  -e SPACES_ACCESS_KEY="$SPACES_ACCESS_KEY" \
  -e SPACES_SECRET_KEY="$SPACES_SECRET_KEY" \
  -e SPACES_ENDPOINT="$SPACES_ENDPOINT" \
  -e SPACES_BUCKET="$SPACES_BUCKET" \
  -e MODEL_PATH="$MODEL_PATH" \
  legal-embedding-serving:latest \
  python download_model_from_spaces.py

# Verify model ƒë√£ download
ls -la models/
```

**üí° Gi·∫£i th√≠ch:**
- `--rm`: T·ª± ƒë·ªông x√≥a container sau khi ch·∫°y xong
- `-v $(pwd)/models:/app/models`: Mount th∆∞ m·ª•c models ƒë·ªÉ l∆∞u file download
- C√°c `-e`: Pass environment variables v√†o container
- `python download_model_from_spaces.py`: Override CMD ƒë·ªÉ ch·∫°y script download thay v√¨ serve

**üìã Output mong ƒë·ª£i:**
```
‚úÖ ƒê√£ k·∫øt n·ªëi v·ªõi Spaces: https://sgp1.digitaloceanspaces.com
üìã Li·ªát k√™ models c√≥ s·∫µn trong bucket 'legal-datalake'...
‚úÖ T√¨m th·∫•y X model(s):
   1. models/legal-embedding-v1
   2. models/legal-embedding-v2
üì• ƒêang download model t·ª´ 'models/legal-embedding-v2'...
...
‚úÖ Download ho√†n t·∫•t!
```

### 8.3. Deploy Serving API v·ªõi Docker Compose (Recommended)
```bash
# Start service v·ªõi docker-compose
docker-compose -f docker-compose.serving.yml up -d

# Check logs
docker-compose -f docker-compose.serving.yml logs -f

# Check status
docker-compose -f docker-compose.serving.yml ps
```

### 8.4. Ho·∫∑c ch·∫°y tr·ª±c ti·∫øp v·ªõi Docker (Alternative)
```bash
# Run container ƒë·ªÉ serving API
docker run -d \
  --name legal-embedding-api \
  -p 5000:5000 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  -e MODEL_PATH=/app/models \
  -e API_HOST=0.0.0.0 \
  -e API_PORT=5000 \
  -e MAX_BATCH_SIZE=32 \
  --restart unless-stopped \
  legal-embedding-serving:latest

# Check logs
docker logs -f legal-embedding-api

# Check container status
docker ps | grep legal-embedding-api
```

### 8.5. Verify API is running
```bash
# Test health endpoint t·ª´ trong droplet
curl http://localhost:5000/health

# Expected output:
# {
#   "status": "healthy",
#   "model_loaded": true,
#   "device": "cpu",
#   "embedding_dim": 1024
# }
```

**‚è∞ Th·ªùi gian kh·ªüi ƒë·ªông:**
- **Model loading**: 30-60 gi√¢y
- **API ready**: 1-2 ph√∫t

### 8.6. üî• M·ªû FIREWALL ƒë·ªÉ Serving ra b√™n ngo√†i

**B∆∞·ªõc n√†y R·∫§T QUAN TR·ªåNG** - N·∫øu kh√¥ng l√†m th√¨ API ch·ªâ ch·∫°y local!

```bash
# Ki·ªÉm tra firewall status
ufw status

# N·∫øu firewall ch∆∞a active ho·∫∑c ch∆∞a config:
# Allow SSH (QUAN TR·ªåNG - l√†m tr∆∞·ªõc khi enable ufw!)
ufw allow OpenSSH
ufw allow 22/tcp

# Allow API port
ufw allow 5000/tcp

# Enable firewall
ufw --force enable

# Verify firewall rules
ufw status verbose
```

**üìã Expected output:**
```
Status: active

To                         Action      From
--                         ------      ----
22/tcp                     ALLOW       Anywhere
5000/tcp                   ALLOW       Anywhere
OpenSSH                    ALLOW       Anywhere
```

### 8.7. üåê Test API t·ª´ b√™n ngo√†i

```bash
# Test t·ª´ m√°y local c·ªßa b·∫°n (thay YOUR_DROPLET_IP)
curl http://YOUR_DROPLET_IP:5000/health

# Test embedding endpoint
curl -X POST http://YOUR_DROPLET_IP:5000/embed \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["Lu·∫≠t D√¢n s·ª± nƒÉm 2015"]
  }'
```

**‚úÖ N·∫øu th√†nh c√¥ng, b·∫°n s·∫Ω th·∫•y:**
- `/health` tr·∫£ v·ªÅ status healthy
- `/embed` tr·∫£ v·ªÅ array of embeddings

**üîß Troubleshooting:**
```bash
# N·∫øu kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c t·ª´ b√™n ngo√†i:

# 1. Check container c√≥ ƒëang ch·∫°y kh√¥ng
docker ps | grep legal-embedding-api

# 2. Check port mapping
docker port legal-embedding-api

# 3. Check firewall
ufw status verbose

# 4. Check logs
docker logs legal-embedding-api

# 5. Test t·ª´ trong droplet tr∆∞·ªõc
curl http://localhost:5000/health

# 6. N·∫øu model kh√¥ng t·ªìn t·∫°i, download l·∫°i
docker run --rm \
  -v $(pwd)/models:/app/models \
  --env-file .env.serving \
  legal-embedding-serving:latest \
  python download_model_from_spaces.py

# 7. Restart API container
docker restart legal-embedding-api
```

**üí° L∆∞u √Ω b·∫£o m·∫≠t:**
- Port 5000 ƒëang m·ªü c√¥ng khai ra internet
- Consider th√™m authentication/API key n·∫øu c·∫ßn
- Ho·∫∑c ch·ªâ allow IP c·ª• th·ªÉ:
```bash
# Ch·ªâ allow t·ª´ IP c·ª• th·ªÉ
ufw delete allow 5000/tcp
ufw allow from YOUR_BACKEND_IP to any port 5000
```

---

## B∆∞·ªõc 9: Test v√† Monitor Serving API

### 9.1. Test nhanh v·ªõi script
```bash
# Tr√™n m√°y local, clone repo n·∫øu ch∆∞a c√≥
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 9.2. Ch·∫°y test suite ƒë·∫ßy ƒë·ªß (Python)
```bash
# Test t·ª´ local (tr√™n m√°y local c·ªßa b·∫°n, kh√¥ng ph·∫£i droplet)
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
python3 test_api.py http://YOUR_DROPLET_IP:5000
```

### 9.3. Test th·ªß c√¥ng v·ªõi curl

**üîç Endpoint 1: Health Check**
```bash
# Check xem API c√≥ s·ªëng kh√¥ng
curl http://YOUR_DROPLET_IP:5000/health
```

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cpu",
  "embedding_dim": 1024,
  "timestamp": 1234567890.123
}
```

**üìù Endpoint 2: Generate Embeddings**
```bash
# T·∫°o embedding vectors cho text
curl -X POST http://YOUR_DROPLET_IP:5000/embed \
  -H "Content-Type: application/json" \
  -d '{
    "texts": [
      "Lu·∫≠t D√¢n s·ª± nƒÉm 2015",
      "B·ªô lu·∫≠t H√¨nh s·ª± nƒÉm 2017"
    ]
  }'
```

**Response:**
```json
{
  "embeddings": [
    [0.123, -0.456, 0.789, ...],  // 1024 dimensions
    [0.234, -0.567, 0.890, ...]   // 1024 dimensions
  ],
  "processing_time": 0.123,
  "count": 2
}
```

**üî¢ Endpoint 3: Calculate Similarity**
```bash
# T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c c√¢u
curl -X POST http://YOUR_DROPLET_IP:5000/similarity \
  -H "Content-Type: application/json" \
  -d '{
    "texts1": ["Lu·∫≠t D√¢n s·ª± v·ªÅ quy·ªÅn s·ªü h·ªØu"],
    "texts2": ["Lu·∫≠t D√¢n  s·ª±"]
  }'
```

**Response:**
```json
{
  "similarities": [
    [0.85, 0.23]  // similarities[i][j] = similarity(texts1[i], texts2[j])
  ],
  "processing_time": 0.089,
  "shape": [1, 2]
}
```

**üí° C√°ch s·ª≠ d·ª•ng trong code Python:**
```python
import requests

API_URL = "http://YOUR_DROPLET_IP:5000"

# 1. Generate embeddings
response = requests.post(
    f"{API_URL}/embed",
    json={"texts": ["Lu·∫≠t D√¢n s·ª±", "B·ªô lu·∫≠t H√¨nh s·ª±"]}
)
embeddings = response.json()["embeddings"]
print(f"Got {len(embeddings)} embeddings")

# 2. Calculate similarity
response = requests.post(
    f"{API_URL}/similarity",
    json={
        "texts1": ["Quy·ªÅn s·ªü h·ªØu t√†i s·∫£n"],
        "texts2": ["T√†i s·∫£n ri√™ng", "T√†i s·∫£n chung", "Quy·ªÅn k·∫ø th·ª´a"]
    }
)
similarities = response.json()["similarities"]
print(f"Similarities: {similarities}")

# 3. Find most similar
query = "Lu·∫≠t v·ªÅ ƒë·∫•t ƒëai"
candidates = ["Quy ƒë·ªãnh v·ªÅ nh√† ƒë·∫•t", "B·ªô lu·∫≠t H√¨nh s·ª±", "Lu·∫≠t ƒê·∫•t ƒëai 2013"]

response = requests.post(
    f"{API_URL}/similarity",
    json={"texts1": [query], "texts2": candidates}
)
scores = response.json()["similarities"][0]
best_idx = scores.index(max(scores))
print(f"Most similar: {candidates[best_idx]} (score: {scores[best_idx]:.3f})")
```

### 9.3. Monitor API logs
```bash
# V·ªõi docker-compose
docker-compose -f docker-compose.serving.yml logs -f

# V·ªõi docker run
docker logs -f legal-embedding-api

# Ho·∫∑c check file logs
tail -f logs/serve_model.log
```

### 9.4. Monitor system resources
```bash
# Monitor CPU, Memory
watch -n 5 'top -n 1 | head -20'

# Monitor Docker stats
docker stats legal-embedding-api

# Check disk usage
df -h
```

### 9.5. C·∫•u h√¨nh Firewall (B·∫ÆT BU·ªòC cho production)
```bash
# Ki·ªÉm tra firewall hi·ªán t·∫°i
ufw status

# Allow SSH (QUAN TR·ªåNG - ph·∫£i l√†m tr∆∞·ªõc!)
ufw allow OpenSSH
ufw allow 22/tcp

# Allow API port
ufw allow 5000/tcp

# Enable firewall
ufw --force enable

# Verify
ufw status verbose
```

**üîí T√πy ch·ªçn b·∫£o m·∫≠t cao h∆°n:**
```bash
# Ch·ªâ allow API t·ª´ IP backend c·ªßa b·∫°n
ufw delete allow 5000/tcp
ufw allow from YOUR_BACKEND_SERVER_IP to any port 5000

# Ho·∫∑c allow t·ª´ m·ªôt subnet
ufw allow from 10.0.0.0/8 to any port 5000

# Rate limiting ƒë·ªÉ ch·ªëng DDoS
ufw limit 5000/tcp
```

---

## B∆∞·ªõc 10: Cleanup v√† Best Practices

### 10.1. X√≥a GPU Droplet sau khi training xong
```bash
# Sau khi model ƒë√£ upload l√™n Spaces v√† verify th√†nh c√¥ng
# V√†o Digital Ocean Dashboard:
# 1. Ch·ªçn GPU Droplet
# 2. Click "Destroy"
# 3. Confirm deletion
# 
# L√Ω do: GPU Droplet r·∫•t ƒë·∫Øt ($72-144/month)
# Ch·ªâ c·∫ßn trong qu√° tr√¨nh training
```

### 10.2. Backup v√† Update Model

**Khi c√≥ model m·ªõi:**
```bash
# SSH v√†o CPU droplet
ssh root@CPU_DROPLET_IP
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Backup model c≈© (optional)
mv models models_backup_$(date +%Y%m%d)
mkdir -p models

# Download model m·ªõi b·∫±ng Docker container
source .env.serving
docker run --rm \
  -v $(pwd)/models:/app/models \
  -e SPACES_ACCESS_KEY="$SPACES_ACCESS_KEY" \
  -e SPACES_SECRET_KEY="$SPACES_SECRET_KEY" \
  -e SPACES_ENDPOINT="$SPACES_ENDPOINT" \
  -e SPACES_BUCKET="$SPACES_BUCKET" \
  -e MODEL_PATH="$MODEL_PATH" \
  legal-embedding-serving:latest \
  python download_model_from_spaces.py

# Restart service
docker-compose -f docker-compose.serving.yml restart
# Ho·∫∑c n·∫øu d√πng docker run:
# docker restart legal-embedding-api

# Verify
curl http://localhost:5000/health
```

### 10.3. Auto-restart policy
```bash
# Docker Compose ƒë√£ config restart: unless-stopped
# Container s·∫Ω t·ª± ƒë·ªông restart n·∫øu:
# - Droplet reboot
# - Container crash
# - Docker daemon restart
```

### 10.4. Best Practices

**‚úÖ Security:**
- S·ª≠ d·ª•ng SSH key thay v√¨ password
- Enable firewall v·ªõi `ufw`
- Gi·ªõi h·∫°n access API b·∫±ng IP whitelist ho·∫∑c API key
- ƒê·ªãnh k·ª≥ update security patches: `apt update && apt upgrade`

**‚úÖ Performance:**
- Monitor CPU/Memory usage ƒë·ªãnh k·ª≥
- Adjust `MAX_BATCH_SIZE` d·ª±a tr√™n RAM available
- Consider upgrade droplet n·∫øu performance kh√¥ng ƒë·ªß

**‚úÖ Cost Optimization:**
- **X√≥a GPU droplet ngay** sau training
- CPU droplet: $24-48/month (r·∫ª h∆°n nhi·ªÅu)
- Backup models l√™n Spaces (cheap storage)

**‚úÖ Monitoring:**
```bash
# Setup simple monitoring script
cat > /root/monitor.sh << 'EOF'
#!/bin/bash
while true; do
  echo "=== $(date) ==="
  curl -s http://localhost:5000/health || echo "API DOWN!"
  docker stats --no-stream legal-embedding-api
  echo ""
  sleep 300  # Check every 5 minutes
done
EOF

chmod +x /root/monitor.sh

# Run in background
nohup /root/monitor.sh > /root/monitor.log 2>&1 &
```

### 10.5. Troubleshooting Common Issues

**API kh√¥ng start:**
```bash
# Check logs
docker logs legal-embedding-api

# Common issues:
# 1. Model kh√¥ng t·ªìn t·∫°i -> Download l·∫°i
# 2. Out of memory -> Reduce MAX_BATCH_SIZE ho·∫∑c upgrade droplet
# 3. Port conflict -> Change API_PORT trong .env.serving
```

**Performance ch·∫≠m:**
```bash
# Check system resources
htop
docker stats

# Solutions:
# 1. Upgrade to bigger droplet (4GB -> 8GB RAM)
# 2. Reduce MAX_BATCH_SIZE
# 3. Optimize model (quantization - advanced)
```

**Model outdated:**
```bash
# Download v√† deploy model m·ªõi b·∫±ng Docker container
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
source .env.serving

docker run --rm \
  -v $(pwd)/models:/app/models \
  --env-file .env.serving \
  legal-embedding-serving:latest \
  python download_model_from_spaces.py

docker-compose -f docker-compose.serving.yml restart
# Ho·∫∑c: docker restart legal-embedding-api
```

---

## üìä Chi ph√≠ d·ª± ki·∫øn

| Service | Size | Cost/month | Usage |
|---------|------|------------|-------|
| **GPU Droplet** | V100, 8GB RAM | $72 | **T·∫°m th·ªùi** (1-2 gi·ªù) ‚âà $0.1 |
| **CPU Droplet** | 4GB RAM, 2 vCPUs | $24 | **L√¢u d√†i** |
| **CPU Droplet** | 8GB RAM, 4 vCPUs | $48 | **Recommended** |
| **Spaces Storage** | 250GB | $5 | Models + Data |

**üí∞ Total Cost: ~$29-53/month** (ch·ªâ tr·∫£ CPU serving + storage)

---

## üéâ Ho√†n th√†nh!

B·∫°n ƒë√£ c√≥:
- ‚úÖ GPU Droplet ƒë·ªÉ training (x√≥a sau khi xong)
- ‚úÖ Model ƒë∆∞·ª£c l∆∞u an to√†n tr√™n Spaces
- ‚úÖ CPU Droplet serving API 24/7
- ‚úÖ Chi ph√≠ t·ªëi ∆∞u (~$29-53/month)

**Next steps:**
- Integrate API v√†o backend c·ªßa b·∫°n
- Setup monitoring & alerting
- Consider load balancer n·∫øu traffic cao

