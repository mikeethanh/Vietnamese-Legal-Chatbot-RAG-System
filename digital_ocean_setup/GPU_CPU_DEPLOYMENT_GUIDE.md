# üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng GPU Droplet cho Training + CPU Droplet cho Serving

## üéØ Chi·∫øn l∆∞·ª£c

**Training**: GPU Droplet (t·∫°m th·ªùi, x√≥a sau khi train xong) ‚Üí Ti·∫øt ki·ªám chi ph√≠
**Serving**: CPU Droplet (ch·∫°y l√¢u d√†i) ‚Üí ·ªîn ƒë·ªãnh v√† r·∫ª

## B∆∞·ªõc 1: T·∫°o GPU Droplet cho Training

### 1.1. V√†o Digital Ocean Dashboard
1. Login: https://cloud.digitalocean.com/
2. Click **"Create"** ‚Üí **"Droplets"**

### 1.2. C·∫•u h√¨nh GPU Droplet
1. **Operating System**: Ubuntu 22.04 (LTS) x64
2. **Plan**: Click tab **"Premium Intel with GPU"**
3. **GPU Options**:
   - **Basic GPU**: $72/month - 1 vCPU, 8GB RAM, 1 GPU (NVIDIA V100) ‚Üê Khuy·∫øn ngh·ªã
   - **Professional GPU**: $144/month - 2 vCPUs, 16GB RAM, 1 GPU (NVIDIA V100) ‚Üê N·∫øu c·∫ßn performance cao
4. **Datacenter**: Singapore (SGP1)
5. **Authentication**: SSH Key (khuy·∫øn ngh·ªã)
6. **Hostname**: `legal-ai-gpu-training`
7. **Tags**: `gpu`, `training`, `temporary`
8. Click **"Create Droplet"**

### 1.3. Ghi l·∫°i th√¥ng tin
- **GPU Droplet IP**: `_______________`

---

## B∆∞·ªõc 2: T·∫°o CPU Droplet cho Serving

### 2.1. T·∫°o CPU Droplet th·ª© 2
1. Click **"Create"** ‚Üí **"Droplets"** (l·∫ßn 2)
2. **Operating System**: Ubuntu 22.04 (LTS) x64
3. **Plan**: Basic - Regular with SSD
4. **Size**: 
   - **$24/month**: 4GB RAM, 2 vCPUs, 80GB SSD ‚Üê Cho serving c∆° b·∫£n
   - **$48/month**: 8GB RAM, 4 vCPUs, 160GB SSD ‚Üê Khuy·∫øn ngh·ªã cho performance t·ªët
5. **Datacenter**: Singapore (SGP1) (c√πng region)
6. **Authentication**: SSH Key (d√πng c√πng key)
7. **Hostname**: `legal-ai-cpu-serving`
8. **Tags**: `cpu`, `serving`, `production`
9. Click **"Create Droplet"**

### 2.2. Ghi l·∫°i th√¥ng tin
- **CPU Droplet IP**: `_______________`

---

## B∆∞·ªõc 3: Setup GPU Droplet cho Training

### 3.1. K·∫øt n·ªëi GPU Droplet
```bash
ssh root@GPU_DROPLET_IP
```

### 3.2. C√†i ƒë·∫∑t NVIDIA Drivers v√† CUDA
```bash
# Update system
apt update && apt upgrade -y

# Install NVIDIA drivers
apt install -y ubuntu-drivers-common
ubuntu-drivers autoinstall

# Reboot ƒë·ªÉ load drivers
reboot
```

**ƒê·ª£i 2-3 ph√∫t v√† k·∫øt n·ªëi l·∫°i:**
```bash
ssh root@GPU_DROPLET_IP
```

### 3.3. Verify GPU
```bash
# Check GPU
nvidia-smi
```

### 3.4. C√†i ƒë·∫∑t Docker v·ªõi GPU support
```bash
# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
&& curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add - \
&& curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list

apt update && apt install -y nvidia-docker2
systemctl restart docker

# Test GPU in Docker
docker run --rm --gpus all nvidia/cuda:13.0.1-base-ubuntu22.04 nvidia-smi
```

---

## B∆∞·ªõc 4: Setup Repository tr√™n GPU Droplet

### 4.1. Clone repository
```bash
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 4.2. C·∫•u h√¨nh environment
```bash
cp .env.template .env
nano .env
```

### 4.3. T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
```bash
mkdir -p data models logs
```

---

## B∆∞·ªõc 5: Setup GPU Training Environment

### 5.1. Ki·ªÉm tra file training script
```bash
# Ki·ªÉm tra file training script c√≥ t·ªìn t·∫°i
ls -la train_embedding_gpu.py
```

### 5.2. Ki·ªÉm tra requirements file
```bash
# S·ª≠ d·ª•ng requirements_gpu.txt cho GPU training
ls -la requirements_gpu.txt
```
## B∆∞·ªõc 6: Training tr√™n GPU Droplet

### 6.1. Load environment variables
```bash
# Load environment variables
source .env

# Verify environment variables
echo "üîç Checking environment variables..."
echo "SPACES_ACCESS_KEY: ${SPACES_ACCESS_KEY:0:10}..." 
echo "SPACES_SECRET_KEY: ${SPACES_SECRET_KEY:0:10}..."
echo "SPACES_BUCKET: $SPACES_BUCKET"
echo "BASE_MODEL: $BASE_MODEL"
```

### 6.2. Build GPU image
```bash
# Build v·ªõi verbose output ƒë·ªÉ debug
docker build -f Dockerfile.gpu-training -t legal-embedding-gpu:latest . --no-cache

# Ki·ªÉm tra image ƒë√£ build th√†nh c√¥ng
docker images | grep legal-embedding-gpu
```

### 6.3. Test GPU access trong Docker
```bash
# Test GPU tr∆∞·ªõc khi training
docker run --rm --gpus all legal-embedding-gpu:latest nvidia-smi

# Test PyTorch GPU access
docker run --rm --gpus all legal-embedding-gpu:latest python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA devices: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'Device name: {torch.cuda.get_device_name(0)}')
"
```

### 6.4. Run training v·ªõi GPU (method 1: Direct run)
```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Load environment variables
source .env

# Run training v·ªõi full config t·ª´ .env
docker run --gpus all \
  --name legal-gpu-training \
  -v $(pwd)/data:/tmp/data \
  -v $(pwd)/models:/tmp/model \
  -v $(pwd)/logs:/tmp/logs \
  -v $(pwd)/.env:/app/.env:ro \
  -e SPACES_ACCESS_KEY="$SPACES_ACCESS_KEY" \
  -e SPACES_SECRET_KEY="$SPACES_SECRET_KEY" \
  -e SPACES_ENDPOINT="$SPACES_ENDPOINT" \
  -e SPACES_BUCKET="$SPACES_BUCKET" \
  -e BASE_MODEL="$BASE_MODEL" \
  -e MODEL_PATH="$MODEL_PATH" \
  -e EPOCHS="$EPOCHS" \
  -e GPU_BATCH_SIZE="$GPU_BATCH_SIZE" \
  -e LEARNING_RATE="$LEARNING_RATE" \
  -e WARMUP_STEPS="$WARMUP_STEPS" \
  -e MAX_SEQ_LENGTH="$MAX_SEQ_LENGTH" \
  -e GRADIENT_ACCUMULATION_STEPS="$GRADIENT_ACCUMULATION_STEPS" \
  -e USE_FP16="$USE_FP16" \
  -e USE_GPU="$USE_GPU" \
  -e CUDA_VISIBLE_DEVICES="$CUDA_VISIBLE_DEVICES" \
  -e MAX_SAMPLES="$MAX_SAMPLES" \
  --rm \
  legal-embedding-gpu:latest
```


### 6.6. Monitor training (trong terminal kh√°c)
```bash
# Terminal 1: Monitor GPU usage
watch -n 5 nvidia-smi

# Terminal 2: Monitor Docker logs
docker logs -f legal-gpu-training

# Terminal 3: Monitor system resources
watch -n 10 'echo "=== CPU/Memory ===" && top -n 1 | head -5 && echo "=== Disk ===" && df -h'
```

### 6.7. Training progress tracking
```bash
# Ki·ªÉm tra training progress
ls -la models/
tail -f logs/training.log

# Ki·ªÉm tra model ƒë√£ upload l√™n Spaces
# (N·∫øu training script c√≥ auto-upload)
```

**‚è∞ Th·ªùi gian training:**
- **GPU V100**: 15-30 ph√∫t
- **GPU H100**: 8-15 ph√∫t  
- **Batch size**: C√≥ th·ªÉ tƒÉng l√™n 128+ v·ªõi GPU H100

**üö® Troubleshooting:**
```bash
# N·∫øu training fail, check logs
docker logs legal-gpu-training

# Ki·ªÉm tra GPU memory
nvidia-smi

# Restart n·∫øu c·∫ßn
docker stop legal-gpu-training
docker rm legal-gpu-training
# R·ªìi ch·∫°y l·∫°i command ·ªü b∆∞·ªõc 6.4
```

---

## B∆∞·ªõc 7: Setup CPU Droplet v√† Download Model t·ª´ Spaces

### 7.1. K·∫øt n·ªëi CPU Droplet
```bash
ssh root@CPU_DROPLET_IP
```

### 7.2. C√†i ƒë·∫∑t Docker
```bash
# Update system
apt update && apt upgrade -y

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Verify Docker installation
docker --version
docker run hello-world
```

### 7.3. Clone repository
```bash
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 7.4. C·∫•u h√¨nh environment cho serving
```bash
# Copy template
cp .env.serving.template .env.serving

# Edit v·ªõi th√¥ng tin c·ªßa b·∫°n
nano .env.serving
```

**C·∫ßn ƒëi·ªÅn c√°c th√¥ng tin sau trong `.env.serving`:**
```bash
SPACES_ACCESS_KEY=your_access_key_here
SPACES_SECRET_KEY=your_secret_key_here
SPACES_ENDPOINT=https://sgp1.digitaloceanspaces.com
SPACES_BUCKET=legal-datalake

# ƒê·ªÉ tr·ªëng ƒë·ªÉ t·ª± ƒë·ªông l·∫•y model m·ªõi nh·∫•t
MODEL_PATH=

# API config
API_HOST=0.0.0.0
API_PORT=5000
MAX_BATCH_SIZE=32
```

### 7.5. Download model t·ª´ Spaces
```bash
# Load environment variables
source .env.serving

# T·∫°o th∆∞ m·ª•c models
mkdir -p models logs

# Download model (s·∫Ω t·ª± ƒë·ªông l·∫•y model m·ªõi nh·∫•t)
python3 download_model_from_spaces.py

# Verify model ƒë√£ download
ls -la models/
```

**üí° L∆∞u √Ω:**
- Script s·∫Ω t·ª± ƒë·ªông list t·∫•t c·∫£ models c√≥ s·∫µn trong Spaces
- N·∫øu kh√¥ng ch·ªâ ƒë·ªãnh `MODEL_PATH`, n√≥ s·∫Ω ch·ªçn model m·ªõi nh·∫•t
- Model s·∫Ω ƒë∆∞·ª£c download v√†o th∆∞ m·ª•c `./models/`

---

## B∆∞·ªõc 8: Deploy Serving API tr√™n CPU Droplet

### 8.1. Build Docker image
```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Build image
docker build -f Dockerfile.cpu-serving -t legal-embedding-serving:latest .

# Verify image ƒë√£ build
docker images | grep legal-embedding-serving
```

### 8.2. Ch·∫°y API v·ªõi Docker Compose (Recommended)
```bash
# Start service v·ªõi docker-compose
docker-compose -f docker-compose.serving.yml up -d

# Check logs
docker-compose -f docker-compose.serving.yml logs -f

# Check status
docker-compose -f docker-compose.serving.yml ps
```

### 8.3. Ho·∫∑c ch·∫°y tr·ª±c ti·∫øp v·ªõi Docker (Alternative)
```bash
# Run container
docker run -d \
  --name legal-embedding-api \
  -p 5000:5000 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  --env-file .env.serving \
  --restart unless-stopped \
  legal-embedding-serving:latest

# Check logs
docker logs -f legal-embedding-api

# Check container status
docker ps | grep legal-embedding-api
```

### 8.4. Verify API is running
```bash
# Test health endpoint
curl http://localhost:5000/health

# Expected output:
# {
#   "status": "healthy",
#   "model_loaded": true,
#   "device": "cpu",
#   "embedding_dim": 1024
# }
```

**‚è∞ Th·ªùi gian kh·ªüi ƒë·ªông:**
- **Model loading**: 30-60 gi√¢y
- **API ready**: 1-2 ph√∫t

---

## B∆∞·ªõc 9: Test v√† Monitor Serving API

### 9.1. Ch·∫°y test suite
```bash
# Test t·ª´ local (tr√™n CPU droplet)
python3 test_api.py http://localhost:5000

# Test t·ª´ m√°y kh√°c (thay YOUR_CPU_DROPLET_IP)
python3 test_api.py http://YOUR_CPU_DROPLET_IP:5000
```

### 9.2. Test th·ªß c√¥ng v·ªõi curl

**Test embedding:**
```bash
curl -X POST http://localhost:5000/embed \
  -H "Content-Type: application/json" \
  -d '{
    "texts": [
      "Lu·∫≠t D√¢n s·ª± nƒÉm 2015",
      "B·ªô lu·∫≠t H√¨nh s·ª± nƒÉm 2017"
    ]
  }'
```

**Test similarity:**
```bash
curl -X POST http://localhost:5000/similarity \
  -H "Content-Type: application/json" \
  -d '{
    "texts1": ["Lu·∫≠t D√¢n s·ª± v·ªÅ quy·ªÅn s·ªü h·ªØu"],
    "texts2": ["Quy ƒë·ªãnh v·ªÅ t√†i s·∫£n", "Lu·∫≠t H√¨nh s·ª±"]
  }'
```

### 9.3. Monitor API logs
```bash
# V·ªõi docker-compose
docker-compose -f docker-compose.serving.yml logs -f

# V·ªõi docker run
docker logs -f legal-embedding-api

# Ho·∫∑c check file logs
tail -f logs/serve_model.log
```

### 9.4. Monitor system resources
```bash
# Monitor CPU, Memory
watch -n 5 'top -n 1 | head -20'

# Monitor Docker stats
docker stats legal-embedding-api

# Check disk usage
df -h
```

### 9.5. C·∫•u h√¨nh Firewall (Optional nh∆∞ng recommended)
```bash
# Allow SSH
ufw allow OpenSSH

# Allow API port
ufw allow 5000/tcp

# Enable firewall
ufw enable

# Check status
ufw status
```

---

## B∆∞·ªõc 10: Cleanup v√† Best Practices

### 10.1. X√≥a GPU Droplet sau khi training xong
```bash
# Sau khi model ƒë√£ upload l√™n Spaces v√† verify th√†nh c√¥ng
# V√†o Digital Ocean Dashboard:
# 1. Ch·ªçn GPU Droplet
# 2. Click "Destroy"
# 3. Confirm deletion
# 
# L√Ω do: GPU Droplet r·∫•t ƒë·∫Øt ($72-144/month)
# Ch·ªâ c·∫ßn trong qu√° tr√¨nh training
```

### 10.2. Backup v√† Update Model

**Khi c√≥ model m·ªõi:**
```bash
# SSH v√†o CPU droplet
ssh root@CPU_DROPLET_IP
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Backup model c≈© (optional)
mv models models_backup_$(date +%Y%m%d)

# Download model m·ªõi
mkdir -p models
python3 download_model_from_spaces.py

# Restart service
docker-compose -f docker-compose.serving.yml restart

# Verify
curl http://localhost:5000/health
```

### 10.3. Auto-restart policy
```bash
# Docker Compose ƒë√£ config restart: unless-stopped
# Container s·∫Ω t·ª± ƒë·ªông restart n·∫øu:
# - Droplet reboot
# - Container crash
# - Docker daemon restart
```

### 10.4. Best Practices

**‚úÖ Security:**
- S·ª≠ d·ª•ng SSH key thay v√¨ password
- Enable firewall v·ªõi `ufw`
- Gi·ªõi h·∫°n access API b·∫±ng IP whitelist ho·∫∑c API key
- ƒê·ªãnh k·ª≥ update security patches: `apt update && apt upgrade`

**‚úÖ Performance:**
- Monitor CPU/Memory usage ƒë·ªãnh k·ª≥
- Adjust `MAX_BATCH_SIZE` d·ª±a tr√™n RAM available
- Consider upgrade droplet n·∫øu performance kh√¥ng ƒë·ªß

**‚úÖ Cost Optimization:**
- **X√≥a GPU droplet ngay** sau training
- CPU droplet: $24-48/month (r·∫ª h∆°n nhi·ªÅu)
- Backup models l√™n Spaces (cheap storage)

**‚úÖ Monitoring:**
```bash
# Setup simple monitoring script
cat > /root/monitor.sh << 'EOF'
#!/bin/bash
while true; do
  echo "=== $(date) ==="
  curl -s http://localhost:5000/health || echo "API DOWN!"
  docker stats --no-stream legal-embedding-api
  echo ""
  sleep 300  # Check every 5 minutes
done
EOF

chmod +x /root/monitor.sh

# Run in background
nohup /root/monitor.sh > /root/monitor.log 2>&1 &
```

### 10.5. Troubleshooting Common Issues

**API kh√¥ng start:**
```bash
# Check logs
docker logs legal-embedding-api

# Common issues:
# 1. Model kh√¥ng t·ªìn t·∫°i -> Download l·∫°i
# 2. Out of memory -> Reduce MAX_BATCH_SIZE ho·∫∑c upgrade droplet
# 3. Port conflict -> Change API_PORT trong .env.serving
```

**Performance ch·∫≠m:**
```bash
# Check system resources
htop
docker stats

# Solutions:
# 1. Upgrade to bigger droplet (4GB -> 8GB RAM)
# 2. Reduce MAX_BATCH_SIZE
# 3. Optimize model (quantization - advanced)
```

**Model outdated:**
```bash
# Download v√† deploy model m·ªõi
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
python3 download_model_from_spaces.py
docker-compose -f docker-compose.serving.yml restart
```

---

## üìä Chi ph√≠ d·ª± ki·∫øn

| Service | Size | Cost/month | Usage |
|---------|------|------------|-------|
| **GPU Droplet** | V100, 8GB RAM | $72 | **T·∫°m th·ªùi** (1-2 gi·ªù) ‚âà $0.1 |
| **CPU Droplet** | 4GB RAM, 2 vCPUs | $24 | **L√¢u d√†i** |
| **CPU Droplet** | 8GB RAM, 4 vCPUs | $48 | **Recommended** |
| **Spaces Storage** | 250GB | $5 | Models + Data |

**üí∞ Total Cost: ~$29-53/month** (ch·ªâ tr·∫£ CPU serving + storage)

---

## üéâ Ho√†n th√†nh!

B·∫°n ƒë√£ c√≥:
- ‚úÖ GPU Droplet ƒë·ªÉ training (x√≥a sau khi xong)
- ‚úÖ Model ƒë∆∞·ª£c l∆∞u an to√†n tr√™n Spaces
- ‚úÖ CPU Droplet serving API 24/7
- ‚úÖ Chi ph√≠ t·ªëi ∆∞u (~$29-53/month)

**Next steps:**
- Integrate API v√†o backend c·ªßa b·∫°n
- Setup monitoring & alerting
- Consider load balancer n·∫øu traffic cao

