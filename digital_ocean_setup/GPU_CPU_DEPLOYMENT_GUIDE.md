# üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng GPU Droplet cho Training + CPU Droplet cho Serving

## üéØ Chi·∫øn l∆∞·ª£c

**Training**: GPU Droplet (t·∫°m th·ªùi, x√≥a sau khi train xong) ‚Üí Ti·∫øt ki·ªám chi ph√≠
**Serving**: CPU Droplet (ch·∫°y l√¢u d√†i) ‚Üí ·ªîn ƒë·ªãnh v√† r·∫ª

## B∆∞·ªõc 1: T·∫°o GPU Droplet cho Training

### 1.1. V√†o Digital Ocean Dashboard
1. Login: https://cloud.digitalocean.com/
2. Click **"Create"** ‚Üí **"Droplets"**

### 1.2. C·∫•u h√¨nh GPU Droplet
1. **Operating System**: Ubuntu 22.04 (LTS) x64
2. **Plan**: Click tab **"Premium Intel with GPU"**
3. **GPU Options**:
   - **Basic GPU**: $72/month - 1 vCPU, 8GB RAM, 1 GPU (NVIDIA V100) ‚Üê Khuy·∫øn ngh·ªã
   - **Professional GPU**: $144/month - 2 vCPUs, 16GB RAM, 1 GPU (NVIDIA V100) ‚Üê N·∫øu c·∫ßn performance cao
4. **Datacenter**: Singapore (SGP1)
5. **Authentication**: SSH Key (khuy·∫øn ngh·ªã)
6. **Hostname**: `legal-ai-gpu-training`
7. **Tags**: `gpu`, `training`, `temporary`
8. Click **"Create Droplet"**

### 1.3. Ghi l·∫°i th√¥ng tin
- **GPU Droplet IP**: `_______________`

---

## B∆∞·ªõc 2: T·∫°o CPU Droplet cho Serving

### 2.1. T·∫°o CPU Droplet th·ª© 2
1. Click **"Create"** ‚Üí **"Droplets"** (l·∫ßn 2)
2. **Operating System**: Ubuntu 22.04 (LTS) x64
3. **Plan**: Basic - Regular with SSD
4. **Size**: 
   - **$24/month**: 4GB RAM, 2 vCPUs, 80GB SSD ‚Üê Cho serving c∆° b·∫£n
   - **$48/month**: 8GB RAM, 4 vCPUs, 160GB SSD ‚Üê Khuy·∫øn ngh·ªã cho performance t·ªët
5. **Datacenter**: Singapore (SGP1) (c√πng region)
6. **Authentication**: SSH Key (d√πng c√πng key)
7. **Hostname**: `legal-ai-cpu-serving`
8. **Tags**: `cpu`, `serving`, `production`
9. Click **"Create Droplet"**

### 2.2. Ghi l·∫°i th√¥ng tin
- **CPU Droplet IP**: `_______________`

---

## B∆∞·ªõc 3: Setup GPU Droplet cho Training

### 3.1. K·∫øt n·ªëi GPU Droplet
```bash
ssh root@GPU_DROPLET_IP
```

### 3.2. C√†i ƒë·∫∑t NVIDIA Drivers v√† CUDA
```bash
# Update system
apt update && apt upgrade -y

# Install NVIDIA drivers
apt install -y ubuntu-drivers-common
ubuntu-drivers autoinstall

# Reboot ƒë·ªÉ load drivers
reboot
```

**ƒê·ª£i 2-3 ph√∫t v√† k·∫øt n·ªëi l·∫°i:**
```bash
ssh root@GPU_DROPLET_IP
```

### 3.3. Verify GPU
```bash
# Check GPU
nvidia-smi
```

### 3.4. C√†i ƒë·∫∑t Docker v·ªõi GPU support
```bash
# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
&& curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add - \
&& curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list

apt update && apt install -y nvidia-docker2
systemctl restart docker

# Test GPU in Docker
docker run --rm --gpus all nvidia/cuda:13.0.1-base-ubuntu22.04 nvidia-smi
```

---

## B∆∞·ªõc 4: Setup Repository tr√™n GPU Droplet

### 4.1. Clone repository
```bash
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 4.2. C·∫•u h√¨nh environment
```bash
cp .env.template .env
nano .env
```

### 4.3. T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
```bash
mkdir -p data models logs
```

---

## B∆∞·ªõc 5: Setup GPU Training Environment

### 5.1. Ki·ªÉm tra file training script
```bash
# Ki·ªÉm tra file training script c√≥ t·ªìn t·∫°i
ls -la train_embedding_gpu.py
```

### 5.2. Ki·ªÉm tra requirements file
```bash
# S·ª≠ d·ª•ng requirements_gpu.txt cho GPU training
ls -la requirements_gpu.txt

## B∆∞·ªõc 6: Training tr√™n GPU Droplet

### 6.1. Load environment variables
```bash
# Load environment variables
source .env

# Verify environment variables
echo "üîç Checking environment variables..."
echo "SPACES_ACCESS_KEY: ${SPACES_ACCESS_KEY:0:10}..." 
echo "SPACES_SECRET_KEY: ${SPACES_SECRET_KEY:0:10}..."
echo "SPACES_BUCKET: $SPACES_BUCKET"
echo "BASE_MODEL: $BASE_MODEL"
```

### 6.2. Build GPU image
```bash
# Build v·ªõi verbose output ƒë·ªÉ debug
docker build -f Dockerfile.gpu-training -t legal-embedding-gpu:latest . --no-cache

# Ki·ªÉm tra image ƒë√£ build th√†nh c√¥ng
docker images | grep legal-embedding-gpu
```

### 6.3. Test GPU access trong Docker
```bash
# Test GPU tr∆∞·ªõc khi training
docker run --rm --gpus all legal-embedding-gpu:latest nvidia-smi

# Test PyTorch GPU access
docker run --rm --gpus all legal-embedding-gpu:latest python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA devices: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'Device name: {torch.cuda.get_device_name(0)}')
"
```

### 6.4. Run training v·ªõi GPU (method 1: Direct run)
```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c
cd /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup

# Load environment variables
source .env

# Run training v·ªõi full config t·ª´ .env
docker run --gpus all \
  --name legal-gpu-training \
  -v $(pwd)/data:/tmp/data \
  -v $(pwd)/models:/tmp/model \
  -v $(pwd)/logs:/tmp/logs \
  -v $(pwd)/.env:/app/.env:ro \
  -e SPACES_ACCESS_KEY="$SPACES_ACCESS_KEY" \
  -e SPACES_SECRET_KEY="$SPACES_SECRET_KEY" \
  -e SPACES_ENDPOINT="$SPACES_ENDPOINT" \
  -e SPACES_BUCKET="$SPACES_BUCKET" \
  -e BASE_MODEL="$BASE_MODEL" \
  -e MODEL_PATH="$MODEL_PATH" \
  -e EPOCHS="$EPOCHS" \
  -e GPU_BATCH_SIZE="$GPU_BATCH_SIZE" \
  -e LEARNING_RATE="$LEARNING_RATE" \
  -e WARMUP_STEPS="$WARMUP_STEPS" \
  -e MAX_SEQ_LENGTH="$MAX_SEQ_LENGTH" \
  -e GRADIENT_ACCUMULATION_STEPS="$GRADIENT_ACCUMULATION_STEPS" \
  -e USE_FP16="$USE_FP16" \
  -e USE_GPU="$USE_GPU" \
  -e CUDA_VISIBLE_DEVICES="$CUDA_VISIBLE_DEVICES" \
  -e MAX_SAMPLES="$MAX_SAMPLES" \
  --rm \
  legal-embedding-gpu:latest
```


### 6.6. Monitor training (trong terminal kh√°c)
```bash
# Terminal 1: Monitor GPU usage
watch -n 5 nvidia-smi

# Terminal 2: Monitor Docker logs
docker logs -f legal-gpu-training

# Terminal 3: Monitor system resources
watch -n 10 'echo "=== CPU/Memory ===" && top -n 1 | head -5 && echo "=== Disk ===" && df -h'
```

### 6.7. Training progress tracking
```bash
# Ki·ªÉm tra training progress
ls -la models/
tail -f logs/training.log

# Ki·ªÉm tra model ƒë√£ upload l√™n Spaces
# (N·∫øu training script c√≥ auto-upload)
```

**‚è∞ Th·ªùi gian training:**
- **GPU V100**: 15-30 ph√∫t
- **GPU H100**: 8-15 ph√∫t  
- **Batch size**: C√≥ th·ªÉ tƒÉng l√™n 128+ v·ªõi GPU H100

**üö® Troubleshooting:**
```bash
# N·∫øu training fail, check logs
docker logs legal-gpu-training

# Ki·ªÉm tra GPU memory
nvidia-smi

# Restart n·∫øu c·∫ßn
docker stop legal-gpu-training
docker rm legal-gpu-training
# R·ªìi ch·∫°y l·∫°i command ·ªü b∆∞·ªõc 6.4
```

---

## B∆∞·ªõc 7: Setup CPU Droplet cho Serving

### 7.1. K·∫øt n·ªëi CPU Droplet
```bash
ssh root@CPU_DROPLET_IP
```

### 7.2. Setup CPU Droplet
```bash
# Update system
apt update && apt upgrade -y

# Install dependencies
apt install -y git curl wget build-essential

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Install Docker Compose
curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

# Clone repository
cd /root
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup
```

### 7.3. C·∫•u h√¨nh environment
```bash
cp .env.template .env
nano .env
```

**C·∫≠p nh·∫≠t .env cho CPU serving:**
```bash
# Digital Ocean Spaces Configuration
SPACES_ACCESS_KEY=your_spaces_access_key_here
SPACES_SECRET_KEY=your_spaces_secret_key_here
SPACES_ENDPOINT=https://sfo3.digitaloceanspaces.com
SPACES_BUCKET=legal-datalake

# CPU Serving specific
USE_GPU=false
# MODEL_PATH s·∫Ω ƒë∆∞·ª£c l·∫•y t·ª´ k·∫øt qu·∫£ training GPU ·ªü b∆∞·ªõc 6
# V√≠ d·ª•: models/embedding_model_gpu_20241024_143022
# B·∫°n s·∫Ω l·∫•y path n√†y t·ª´ logs c·ªßa GPU training ho·∫∑c check trong Spaces
MODEL_PATH=  # ƒê·ªÉ tr·ªëng, s·∫Ω c·∫≠p nh·∫≠t sau khi c√≥ k·∫øt qu·∫£ training
PORT=5000
BATCH_SIZE=16  # Th·∫•p h∆°n cho CPU
```

**üìã C√°ch l·∫•y MODEL_PATH:**
1. **T·ª´ GPU training logs:** Khi training xong, script s·∫Ω in ra path nh∆∞:
   ```
   üéâ Model uploaded successfully to: models/embedding_model_gpu_20241024_143022
   ```
2. **T·ª´ Digital Ocean Spaces:** V√†o Spaces dashboard ‚Üí legal-datalake ‚Üí models ‚Üí copy t√™n folder m·ªõi nh·∫•t
3. **T·ª´ deploy script:** Script `deploy.sh` c√≥ th·ªÉ t·ª± ƒë·ªông detect latest model

---

## B∆∞·ªõc 8: Transfer Model t·ª´ GPU sang CPU Droplet

### 8.1. Sau khi training xong tr√™n GPU - L·∫•y MODEL_PATH

**Tr√™n GPU Droplet:**
```bash
# Ki·ªÉm tra model ƒë√£ upload l√™n Spaces
ls -la /tmp/model/

# Ghi l·∫°i model path t·ª´ training logs
tail -n 20 /tmp/logs/training.log | grep "Model uploaded successfully"
# K·∫øt qu·∫£ s·∫Ω l√†: üéâ Model uploaded successfully to: models/embedding_model_gpu_20241024_143022

# Ho·∫∑c check tr·ª±c ti·∫øp tr√™n Spaces b·∫±ng AWS CLI
aws s3 ls s3://legal-datalake/models/ --endpoint-url=https://sgp1.digitaloceanspaces.com
```

**üìù Ghi l·∫°i MODEL_PATH:** `models/embedding_model_gpu_YYYYMMDD_HHMMSS`

**V√≠ d·ª•:** `models/embedding_model_gpu_20241024_143022`

### 8.2. C·∫≠p nh·∫≠t MODEL_PATH v√† deploy tr√™n CPU Droplet

**Tr√™n CPU Droplet:**
```bash
# C·∫≠p nh·∫≠t MODEL_PATH trong .env file v·ªõi path t·ª´ b∆∞·ªõc 8.1
nano .env

# Th√™m MODEL_PATH v√†o file .env:
# MODEL_PATH=models/embedding_model_gpu_20241024_143022  # Thay b·∫±ng path th·∫≠t t·ª´ b∆∞·ªõc 8.1

# Ho·∫∑c d√πng sed ƒë·ªÉ c·∫≠p nh·∫≠t nhanh
sed -i 's|MODEL_PATH=.*|MODEL_PATH=models/embedding_model_gpu_20241024_143022|g' .env

# Verify c·∫•u h√¨nh
grep MODEL_PATH .env
```

### 8.3. Deploy serving services
```bash
# Build serving image
docker-compose build embedding-server

# Deploy serving services  
./deploy.sh deploy

# Ho·∫∑c d√πng script t·ª± ƒë·ªông download latest model
./deploy.sh download  # T·ª± ƒë·ªông t√¨m model m·ªõi nh·∫•t
./deploy.sh deploy    # Deploy v·ªõi model m·ªõi
```

---

## B∆∞·ªõc 9: Verify v√† Test

### 9.1. Test CPU Serving Droplet
```bash
# Tr√™n CPU Droplet
./deploy.sh health

# Test t·ª´ local
curl http://CPU_DROPLET_IP/health
```

### 9.2. Performance comparison
```bash
# Test embedding speed
python test_api.py http://CPU_DROPLET_IP:5000
```

---

## B∆∞·ªõc 10: Cleanup GPU Droplet

### 10.1. Backup quan tr·ªçng
**Tr√™n GPU Droplet:**
```bash
# Backup logs v√† configs
tar -czf training_backup.tar.gz /tmp/model /tmp/data /root/Vietnamese-Legal-Chatbot-RAG-System/digital_ocean_setup/.env

# Upload backup l√™n Spaces (optional)
aws s3 cp training_backup.tar.gz s3://legal-datalake/backups/ --endpoint-url=https://sgp1.digitaloceanspaces.com
```

### 10.2. Destroy GPU Droplet
1. **V√†o Digital Ocean Dashboard**
2. **Droplets** ‚Üí **legal-ai-gpu-training**
3. **Settings** ‚Üí **Destroy**
4. **Type droplet name** ‚Üí **Destroy**

üí∞ **Ti·∫øt ki·ªám**: Thay v√¨ $72/month GPU li√™n t·ª•c ‚Üí ch·ªâ tr·∫£ $1-2 cho v√†i gi·ªù training

---

## üìä So s√°nh Performance & Cost

### Training Performance
| Ph∆∞∆°ng √°n | Th·ªùi gian | Chi ph√≠/training | GPU Memory |
|-----------|-----------|------------------|------------|
| CPU Droplet | 60-90 ph√∫t | ~$0.50 | 0 GB |
| GPU Droplet | 15-30 ph√∫t | ~$1-2 | 16 GB |

### Serving Performance  
| Ph∆∞∆°ng √°n | Response time | Chi ph√≠/th√°ng | Throughput |
|-----------|---------------|---------------|------------|
| CPU Droplet | 200-500ms | $24-48 | 5-10 req/s |
| GPU Droplet | 50-100ms | $72+ | 20-50 req/s |

### Khuy·∫øn ngh·ªã t·ªëi ∆∞u
- **Training**: GPU Droplet (destroy sau khi d√πng)
- **Serving**: CPU Droplet (ch·∫°y l√¢u d√†i)
- **Re-training**: T·∫°o GPU Droplet m·ªõi khi c·∫ßn

---

## üîÑ Workflow t·ªëi ∆∞u

1. **Monthly/Quarterly**: T·∫°o GPU Droplet ‚Üí Train model m·ªõi ‚Üí Destroy
2. **Daily**: CPU Droplet serving 24/7
3. **Update**: Download model m·ªõi t·ª´ Spaces ‚Üí Restart serving

**üí° L·ª£i √≠ch**: 
- Ti·∫øt ki·ªám 70-80% chi ph√≠
- Training nhanh h∆°n 3-4 l·∫ßn
- Serving ·ªïn ƒë·ªãnh v√† r·∫ª