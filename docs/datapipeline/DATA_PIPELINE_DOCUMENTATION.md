# TÃ i liá»‡u Data Pipeline - Vietnamese Legal Chatbot RAG System

## ğŸ“‹ Tá»•ng quan

Data Pipeline cá»§a há»‡ thá»‘ng Vietnamese Legal Chatbot RAG cÃ³ nhiá»‡m vá»¥ xá»­ lÃ½ vÃ  chuáº©n bá»‹ dá»¯ liá»‡u tá»« cÃ¡c nguá»“n khÃ¡c nhau Ä‘á»ƒ phá»¥c vá»¥ cho viá»‡c training vÃ  triá»ƒn khai chatbot tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam.

## ğŸ¯ Váº¥n Ä‘á» cáº§n giáº£i quyáº¿t

### BÃ i toÃ¡n chia dá»¯ liá»‡u
Dá»¯ liá»‡u cáº§n Ä‘Æ°á»£c chia thÃ nh **3 pháº§n chÃ­nh**:

1. **ğŸ“š Dá»¯ liá»‡u Finetune**: Äá»ƒ training mÃ´ hÃ¬nh hiá»ƒu vÃ  tráº£ lá»i cÃ¢u há»i phÃ¡p luáº­t
2. **ğŸ” Dá»¯ liá»‡u Embedding**: Äá»ƒ táº¡o vector representations cho tÃ¬m kiáº¿m ngá»¯ nghÄ©a  
3. **ğŸ’¾ Dá»¯ liá»‡u RAG**: Äá»ƒ xÃ¢y dá»±ng knowledge base cho há»‡ thá»‘ng Retrieval-Augmented Generation

### Nguá»“n dá»¯ liá»‡u
Pipeline xá»­ lÃ½ dá»¯ liá»‡u tá»« **nhiá»u nguá»“n khÃ¡c nhau**:

#### **Dá»¯ liá»‡u Finetune** (tá»« Hugging Face):
1. **`phuocsang/hoidap-tvpl-20k`** - 20k cáº·p há»i Ä‘Ã¡p phÃ¡p luáº­t tiáº¿ng Viá»‡t (process_finetune_data.ipynb)
2. **`huyhuy123/ViLQA`** - Vietnamese Legal Q&A dataset (process_finetune_data_2.ipynb)  
3. **`chillies/vn-legal-conversation`** - Vietnamese legal conversation data (process_finetune_data_3.ipynb)

#### **Dá»¯ liá»‡u RAG/Embedding** (tá»« Kaggle):
- **`anti-ai/ViNLI-Zalo-supervised`** - Vietnamese legal corpus tá»« file `law_vi.jsonl.gz` (download_embed_data.ipynb)

**ThÃ¡ch thá»©c**: Dá»¯ liá»‡u tá»« nhiá»u nguá»“n khÃ¡c nhau cÃ³ format vÃ  cáº¥u trÃºc khÃ¡c nhau cáº§n Ä‘Æ°á»£c tá»•ng há»£p vÃ  chuáº©n hÃ³a vá» má»™t Ä‘á»‹nh dáº¡ng thá»‘ng nháº¥t.

## ğŸ”§ Chi tiáº¿t cÃ¡c module xá»­ lÃ½

### 1. Module Xá»­ lÃ½ Dá»¯ liá»‡u Finetune

#### ğŸ“ File: `process_finetune_data.ipynb`

ÄÃ¢y lÃ  module quan trá»ng nháº¥t trong pipeline, cÃ³ nhiá»‡m vá»¥ chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ´ thÃ nh Ä‘á»‹nh dáº¡ng Q&A phÃ¹ há»£p cho viá»‡c training chatbot.

#### ğŸ” **PhÃ¢n tÃ­ch dá»¯ liá»‡u (Data Analysis)**

**HÃ m `analyze_text_quality(dataset_split, split_name)`**

```python
def analyze_text_quality(dataset_split, split_name):
    """
    PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng text trong dataset
    
    Args:
        dataset_split: Pháº§n dá»¯ liá»‡u cáº§n phÃ¢n tÃ­ch (train/test)
        split_name: TÃªn cá»§a pháº§n dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹
        
    Returns:
        dict: Thá»‘ng kÃª chi tiáº¿t vá» cháº¥t lÆ°á»£ng dá»¯ liá»‡u
    """
```

**Ket qua**
ğŸ“ˆ PhÃ¢n tÃ­ch Dataset ViLQA (43588 samples):
ğŸ”¸ Äá»™ dÃ i cÃ¢u há»i:
   - Trung bÃ¬nh: 75.7 kÃ½ tá»±
   - Min: 0, Max: 263
   - Median: 71.0
ğŸ”¸ Äá»™ dÃ i cÃ¢u tráº£ lá»i:
   - Trung bÃ¬nh: 888.6 kÃ½ tá»±
   - Min: 0, Max: 20674
   - Median: 673.0
ğŸ”¸ Dá»¯ liá»‡u rá»—ng:
   - CÃ¢u há»i rá»—ng: 48
   - CÃ¢u tráº£ lá»i rá»—ng: 115
ğŸ”¸ CÃ¢u há»i cÃ³ dáº¥u '?': 42502/43588 (97.5%)

**Táº¡i sao cáº§n phÃ¢n tÃ­ch:**
- Hiá»ƒu Ä‘Æ°á»£c Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u trÆ°á»›c khi xá»­ lÃ½
- Thiáº¿t láº­p cÃ¡c ngÆ°á»¡ng lá»c dá»¯ liá»‡u há»£p lÃ½
- PhÃ¡t hiá»‡n cÃ¡c váº¥n Ä‘á» tiá»m áº©n trong dataset

#### ğŸ§¹ **LÃ m sáº¡ch dá»¯ liá»‡u (Data Cleaning)**

**HÃ m `clean_text(text)`**

```python
def clean_text(text):
    """
    LÃ m sáº¡ch vÃ  chuáº©n hÃ³a text
    
    Args:
        text (str): Text cáº§n lÃ m sáº¡ch
        
    Returns:
        str: Text Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch
    """
```

**CÃ¡c bÆ°á»›c xá»­ lÃ½:**
1. **Loáº¡i bá» khoáº£ng tráº¯ng thá»«a**: Sá»­ dá»¥ng `" ".join(text.split())` Ä‘á»ƒ normalize spaces
2. **Chuáº©n hÃ³a kÃ½ tá»± xuá»‘ng dÃ²ng**: Thay tháº¿ `\n`, `\r`, `\t` báº±ng space
3. **Trim space**: Loáº¡i bá» space Ä‘áº§u vÃ  cuá»‘i chuá»—i

**Táº¡i sao cáº§n lÃ m sáº¡ch:**
- Äáº£m báº£o tÃ­nh nháº¥t quÃ¡n trong format
- Loáº¡i bá» noise cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng training
- Chuáº©n hÃ³a Ä‘á»ƒ dá»… dÃ ng xá»­ lÃ½ sau nÃ y

#### ğŸ¯ **Lá»c vÃ  xá»­ lÃ½ dá»¯ liá»‡u (Data Filtering)**

**HÃ m `process_dataset(dataset_split, max_answer_length=5000)`**

```python
def process_dataset(dataset_split, max_answer_length=5000):
    """
    Xá»­ lÃ½ dataset vÃ  lá»c dá»¯ liá»‡u cháº¥t lÆ°á»£ng
    
    Args:
        dataset_split: Dataset cáº§n xá»­ lÃ½
        max_answer_length (int): Äá»™ dÃ i tá»‘i Ä‘a cá»§a cÃ¢u tráº£ lá»i
        
    Returns:
        list: Danh sÃ¡ch cÃ¡c máº«u dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lá»c vÃ  xá»­ lÃ½
    """
```
**ket qua**
âœ… Dataset processed: 43588 â†’ 43420 (giá»¯ láº¡i 99.6%)

ğŸ“Š Thá»‘ng kÃª sau xá»­ lÃ½:
- Tá»•ng sá»‘ máº«u cháº¥t lÆ°á»£ng: 43420

ğŸ”¸ Äá»™ dÃ i cÃ¢u há»i sau xá»­ lÃ½:
   - Trung bÃ¬nh: 75.9 kÃ½ tá»±
   - Min: 10, Max: 263
ğŸ”¸ Äá»™ dÃ i cÃ¢u tráº£ lá»i sau xá»­ lÃ½:
   - Trung bÃ¬nh: 882.7 kÃ½ tá»±
   - Min: 51, Max: 7981

**TiÃªu chÃ­ lá»c:**
- **Äá»™ dÃ i cÃ¢u há»i tá»‘i thiá»ƒu**: >= 10 kÃ½ tá»± (Ä‘áº£m báº£o cÃ¢u há»i cÃ³ Ã½ nghÄ©a)
- **Äá»™ dÃ i cÃ¢u tráº£ lá»i tá»‘i thiá»ƒu**: >= 50 kÃ½ tá»± (Ä‘áº£m báº£o cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§)
- **Äá»™ dÃ i cÃ¢u tráº£ lá»i tá»‘i Ä‘a**: <= 5000 kÃ½ tá»± (trÃ¡nh context quÃ¡ dÃ i)
- **Format cÃ¢u há»i**: Pháº£i káº¿t thÃºc báº±ng dáº¥u '?' (Ä‘áº£m báº£o lÃ  cÃ¢u há»i thá»±c sá»±)

**LÃ½ do cÃ¡c tiÃªu chÃ­:**
- Äáº£m báº£o cháº¥t lÆ°á»£ng dá»¯ liá»‡u training
- TrÃ¡nh overfitting vá»›i cÃ¡c máº«u khÃ´ng chuáº©n
- Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t training vÃ  inference

### 2. Module LÆ°u trá»¯ dá»¯ liá»‡u (Data Storage)

#### ğŸ“¦ **Äá»‹nh dáº¡ng lÆ°u trá»¯ Ä‘a dáº¡ng**

Pipeline há»— trá»£ **2 Ä‘á»‹nh dáº¡ng** chÃ­nh Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ¡c má»¥c Ä‘Ã­ch training khÃ¡c nhau:

#### **Format 1: QA Format (Question-Answer)**

**HÃ m `save_jsonl(data, filepath)`**

```python
def save_jsonl(data, filepath):
    """
    LÆ°u dá»¯ liá»‡u dÆ°á»›i Ä‘á»‹nh dáº¡ng JSONL cÆ¡ báº£n
    
    Structure:
    {
        "question": "CÃ¢u há»i phÃ¡p luáº­t",
        "answer": "CÃ¢u tráº£ lá»i chi tiáº¿t"
    }
    """
```

**Sá»­ dá»¥ng cho:**
- Traditional Q&A training
- Simple fine-tuning approaches
- Evaluation vÃ  testing

#### **Format 2: Instruction Format**

**HÃ m `save_instruction_format(data, filepath)`**

```python
def save_instruction_format(data, filepath):
    """
    LÆ°u dá»¯ liá»‡u dÆ°á»›i Ä‘á»‹nh dáº¡ng instruction tuning
    
    Structure:
    {
        "instruction": "Tráº£ lá»i cÃ¢u há»i phÃ¡p luáº­t sau:",
        "input": "CÃ¢u há»i cá»§a user",
        "output": "CÃ¢u tráº£ lá»i mong muá»‘n"
    }
    """
```

**Táº¡i sao cáº§n Instruction Format:**
- **TÃ­nh nháº¥t quÃ¡n**: MÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡ch tuÃ¢n theo instructions
- **Kháº£ nÄƒng generalization**: MÃ´ hÃ¬nh cÃ³ thá»ƒ Ã¡p dá»¥ng cho cÃ¡c loáº¡i instructions khÃ¡c
- **Cháº¥t lÆ°á»£ng output**: Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  relevance cá»§a cÃ¢u tráº£ lá»i
- **Alignment**: Äáº£m báº£o mÃ´ hÃ¬nh tuÃ¢n theo human preference

### 3. Module Metadata vÃ  Validation

#### ğŸ“Š **Táº¡o Metadata**

Pipeline tá»± Ä‘á»™ng táº¡o metadata chi tiáº¿t bao gá»“m:

```json
{
    "dataset_info": {
        "source": "phuocsang/hoidap-tvpl-20k",
        "description": "Vietnamese Legal Q&A Dataset processed for fine-tuning",
        "total_samples": "Tá»•ng sá»‘ máº«u",
        "train_samples": "Sá»‘ máº«u train",
        "test_samples": "Sá»‘ máº«u test"
    },
    "processing_info": {
        "filters_applied": ["Danh sÃ¡ch cÃ¡c bá»™ lá»c Ä‘Ã£ Ã¡p dá»¥ng"],
        "retention_rate": "Tá»· lá»‡ dá»¯ liá»‡u Ä‘Æ°á»£c giá»¯ láº¡i"
    },
    "file_formats": {
        "qa_format": "MÃ´ táº£ format",
        "instruction_format": "MÃ´ táº£ format", 
        "conversation_format": "MÃ´ táº£ format"
    }
}
```

#### âœ… **Validation dá»¯ liá»‡u**

**HÃ m `validate_jsonl_file(filepath, expected_count)`**

```python
def validate_jsonl_file(filepath, expected_count):
    """
    Kiá»ƒm tra tÃ­nh toÃ n váº¹n cá»§a file JSONL
    
    Validates:
    - JSON format correctness
    - Expected number of records
    - File readability
    """
```

**Kiá»ƒm tra:**
- TÃ­nh há»£p lá»‡ cá»§a JSON format
- Sá»‘ lÆ°á»£ng records matches expected
- Kháº£ nÄƒng Ä‘á»c file
- Encoding UTF-8 Ä‘Ãºng chuáº©n

## ğŸ”„ Workflow tá»•ng thá»ƒ

```
1. Load Dataset tá»« Hugging Face
    â†“
2. PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng dá»¯ liá»‡u (Analysis)
    â†“
3. LÃ m sáº¡ch text (Cleaning) 
    â†“
4. Lá»c theo tiÃªu chÃ­ cháº¥t lÆ°á»£ng (Filtering)
    â†“
5. Chuyá»ƒn Ä‘á»•i sang multiple formats (Transformation)
    â†“
6. LÆ°u trá»¯ vá»›i metadata (Storage)
    â†“
7. Validation vÃ  quality check (Validation)
```

*TÃ i liá»‡u nÃ y mÃ´ táº£ chi tiáº¿t architecture vÃ  implementation cá»§a Data Pipeline trong Vietnamese Legal Chatbot RAG System. Äá»ƒ biáº¿t thÃªm chi tiáº¿t vá» implementation cá»¥ thá»ƒ, vui lÃ²ng tham kháº£o source code trong thÆ° má»¥c `data_pipeline/`.*