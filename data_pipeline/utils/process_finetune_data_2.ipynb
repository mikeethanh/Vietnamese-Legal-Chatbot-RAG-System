{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead8393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"huyhuy123/ViLQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2150733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'ID1', 'Question', 'Answer', 'idx'],\n",
       "        num_rows: 43588\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0e0c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Th√¥ng tin dataset ViLQA:\n",
      "- Total samples: 43588 m·∫´u\n",
      "- Features: ['ID', 'ID1', 'Question', 'Answer', 'idx']\n",
      "\n",
      "üîç Xem m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:\n",
      "ID: 29\n",
      "ID1: 2\n",
      "Question: Th·ª±c hi·ªán c·∫Øt gi·∫£m h·ªì s∆° thay ƒë·ªïi m·ª©c v·ªën ƒëi·ªÅu l·ªá c·ªßa ng√¢n h√†ng h·ª£p t√°c x√£ trong qu√Ω 2 nƒÉm 2024?\n",
      "Answer: CƒÉn c·ª© M·ª•c 3 Ph·∫ßn 3 Ph∆∞∆°ng √°n c·∫Øt gi·∫£m, ƒë∆°n gi·∫£n h√≥a quy ƒë·ªãnh li√™n quan ƒë·∫øn ho·∫°t ƒë·ªông kinh doanh thu...\n",
      "idx: 0\n",
      "\n",
      "üìù M·ªôt v√†i m·∫´u kh√°c:\n",
      "\n",
      "Sample 2:\n",
      "Question: M·∫´u ƒë∆°n ƒë·ªÅ ngh·ªã ch·∫•p thu·∫≠n thay ƒë·ªïi m·ª©c v·ªën ƒëi·ªÅu l·ªá c·ªßa ng√¢n h√†ng h·ª£p t√°c x√£ m·ªõi...\n",
      "Answer: ƒê∆°n ƒë·ªÅ ngh·ªã ch·∫•p thu·∫≠n thay ƒë·ªïi m·ª©c v·ªën ƒëi·ªÅu l·ªá c·ªßa ng√¢n h√†ng h·ª£p t√°c x√£ hi·ªán na...\n",
      "\n",
      "Sample 3:\n",
      "Question: Th·ªèa thu·∫≠n cho vay gi·ªØa kh√°ch h√†ng v√† ng√¢n h√†ng c√≥ ph·∫£i l·∫≠p th√†nh vƒÉn b·∫£n kh√¥ng?...\n",
      "Answer: CƒÉn c·ª© theo kho·∫£n 1, kho·∫£n 2 ƒêi·ªÅu 23 Th√¥ng t∆∞ 39/2016/TT-NHNN, th·ªèa thu·∫≠n cho va...\n",
      "\n",
      "Sample 4:\n",
      "Question: Kh√°ch h√†ng c√≥ th·ªÉ vay ng√¢n h√†ng theo h√¨nh th·ª©c n√†o?...\n",
      "Answer: CƒÉn c·ª© theo ƒêi·ªÅu 10 Th√¥ng t∆∞ 39/2016/TT-NHNN quy ƒë·ªãnh nh∆∞ sau: Nh∆∞ v·∫≠y, kh√°ch h√†...\n"
     ]
    }
   ],
   "source": [
    "# Ph√¢n t√≠ch c·∫•u tr√∫c d·ªØ li·ªáu ViLQA dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üìä Th√¥ng tin dataset ViLQA:\")\n",
    "print(f\"- Total samples: {len(ds['train'])} m·∫´u\")\n",
    "print(f\"- Features: {list(ds['train'].features.keys())}\")\n",
    "\n",
    "print(\"\\nüîç Xem m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:\")\n",
    "sample = ds['train'][0]\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, str) and len(value) > 100:\n",
    "        print(f\"{key}: {value[:100]}...\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nüìù M·ªôt v√†i m·∫´u kh√°c:\")\n",
    "for i in range(1, 4):\n",
    "    sample = ds['train'][i]\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Question: {sample['Question'][:80]}...\")\n",
    "    print(f\"Answer: {sample['Answer'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758df8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Ph√¢n t√≠ch Dataset ViLQA (43588 samples):\n",
      "üî∏ ƒê·ªô d√†i c√¢u h·ªèi:\n",
      "   - Trung b√¨nh: 75.7 k√Ω t·ª±\n",
      "   - Min: 0, Max: 263\n",
      "   - Median: 71.0\n",
      "üî∏ ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi:\n",
      "   - Trung b√¨nh: 888.6 k√Ω t·ª±\n",
      "   - Min: 0, Max: 20674\n",
      "   - Median: 673.0\n",
      "üî∏ D·ªØ li·ªáu r·ªóng:\n",
      "   - C√¢u h·ªèi r·ªóng: 48\n",
      "   - C√¢u tr·∫£ l·ªùi r·ªóng: 115\n",
      "üî∏ C√¢u h·ªèi c√≥ d·∫•u '?': 42502/43588 (97.5%)\n"
     ]
    }
   ],
   "source": [
    "# Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu Question v√† Answer\n",
    "def analyze_vilqa_quality(dataset):\n",
    "    \"\"\"Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu ViLQA\"\"\"\n",
    "    questions = [item['Question'] for item in dataset]\n",
    "    answers = [item['Answer'] for item in dataset]\n",
    "    \n",
    "    print(f\"üìà Ph√¢n t√≠ch Dataset ViLQA ({len(dataset)} samples):\")\n",
    "    \n",
    "    # ƒê·ªô d√†i c√¢u h·ªèi\n",
    "    question_lengths = [len(q) if q else 0 for q in questions]\n",
    "    print(f\"üî∏ ƒê·ªô d√†i c√¢u h·ªèi:\")\n",
    "    print(f\"   - Trung b√¨nh: {np.mean(question_lengths):.1f} k√Ω t·ª±\")\n",
    "    print(f\"   - Min: {min(question_lengths)}, Max: {max(question_lengths)}\")\n",
    "    print(f\"   - Median: {np.median(question_lengths):.1f}\")\n",
    "    \n",
    "    # ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi\n",
    "    answer_lengths = [len(a) if a else 0 for a in answers]\n",
    "    print(f\"üî∏ ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi:\")\n",
    "    print(f\"   - Trung b√¨nh: {np.mean(answer_lengths):.1f} k√Ω t·ª±\")\n",
    "    print(f\"   - Min: {min(answer_lengths)}, Max: {max(answer_lengths)}\")\n",
    "    print(f\"   - Median: {np.median(answer_lengths):.1f}\")\n",
    "    \n",
    "    # Ki·ªÉm tra d·ªØ li·ªáu r·ªóng\n",
    "    empty_questions = sum(1 for q in questions if not q or q.strip() == \"\")\n",
    "    empty_answers = sum(1 for a in answers if not a or a.strip() == \"\")\n",
    "    \n",
    "    print(f\"üî∏ D·ªØ li·ªáu r·ªóng:\")\n",
    "    print(f\"   - C√¢u h·ªèi r·ªóng: {empty_questions}\")\n",
    "    print(f\"   - C√¢u tr·∫£ l·ªùi r·ªóng: {empty_answers}\")\n",
    "    \n",
    "    # Ph√¢n t√≠ch c√¢u h·ªèi k·∫øt th√∫c b·∫±ng d·∫•u ?\n",
    "    questions_with_qmark = sum(1 for q in questions if q and q.strip().endswith('?'))\n",
    "    print(f\"üî∏ C√¢u h·ªèi c√≥ d·∫•u '?': {questions_with_qmark}/{len(questions)} ({questions_with_qmark/len(questions)*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'questions': questions,\n",
    "        'answers': answers,\n",
    "        'question_lengths': question_lengths,\n",
    "        'answer_lengths': answer_lengths,\n",
    "        'empty_questions': empty_questions,\n",
    "        'empty_answers': empty_answers,\n",
    "        'questions_with_qmark': questions_with_qmark\n",
    "    }\n",
    "\n",
    "# Ph√¢n t√≠ch dataset ViLQA\n",
    "vilqa_analysis = analyze_vilqa_quality(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af666f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß ƒêang x·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu ViLQA...\n",
      "‚úÖ Dataset processed: 43588 ‚Üí 43420 (gi·ªØ l·∫°i 99.6%)\n",
      "\n",
      "üìä Th·ªëng k√™ sau x·ª≠ l√Ω:\n",
      "- T·ªïng s·ªë m·∫´u ch·∫•t l∆∞·ª£ng: 43420\n",
      "\n",
      "üî∏ ƒê·ªô d√†i c√¢u h·ªèi sau x·ª≠ l√Ω:\n",
      "   - Trung b√¨nh: 75.9 k√Ω t·ª±\n",
      "   - Min: 10, Max: 263\n",
      "üî∏ ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi sau x·ª≠ l√Ω:\n",
      "   - Trung b√¨nh: 882.7 k√Ω t·ª±\n",
      "   - Min: 51, Max: 7981\n",
      "‚úÖ Dataset processed: 43588 ‚Üí 43420 (gi·ªØ l·∫°i 99.6%)\n",
      "\n",
      "üìä Th·ªëng k√™ sau x·ª≠ l√Ω:\n",
      "- T·ªïng s·ªë m·∫´u ch·∫•t l∆∞·ª£ng: 43420\n",
      "\n",
      "üî∏ ƒê·ªô d√†i c√¢u h·ªèi sau x·ª≠ l√Ω:\n",
      "   - Trung b√¨nh: 75.9 k√Ω t·ª±\n",
      "   - Min: 10, Max: 263\n",
      "üî∏ ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi sau x·ª≠ l√Ω:\n",
      "   - Trung b√¨nh: 882.7 k√Ω t·ª±\n",
      "   - Min: 51, Max: 7981\n"
     ]
    }
   ],
   "source": [
    "# L√†m s·∫°ch v√† x·ª≠ l√Ω d·ªØ li·ªáu ViLQA\n",
    "def clean_text(text):\n",
    "    \"\"\"L√†m s·∫°ch text\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def process_vilqa_dataset(dataset, max_answer_length=8000):\n",
    "    \"\"\"X·ª≠ l√Ω dataset ViLQA v√† l·ªçc d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        # L·∫•y d·ªØ li·ªáu t·ª´ c√°c tr∆∞·ªùng ƒë√∫ng\n",
    "        question = clean_text(item.get('Question', ''))\n",
    "        answer = clean_text(item.get('Answer', ''))\n",
    "        \n",
    "        # L·ªçc d·ªØ li·ªáu theo ti√™u ch√≠ ch·∫•t l∆∞·ª£ng\n",
    "        if (len(question) >= 10 and  # C√¢u h·ªèi √≠t nh·∫•t 10 k√Ω t·ª±\n",
    "            len(answer) >= 50 and    # C√¢u tr·∫£ l·ªùi √≠t nh·∫•t 50 k√Ω t·ª±\n",
    "            len(answer) <= max_answer_length):  # Gi·ªõi h·∫°n ƒë·ªô d√†i tr·∫£ l·ªùi\n",
    "            \n",
    "            processed_data.append({\n",
    "                'question': question,\n",
    "                'answer': answer\n",
    "            })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "print(\"üîß ƒêang x·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu ViLQA...\")\n",
    "\n",
    "# X·ª≠ l√Ω dataset\n",
    "vilqa_processed = process_vilqa_dataset(ds['train'])\n",
    "print(f\"‚úÖ Dataset processed: {len(ds['train'])} ‚Üí {len(vilqa_processed)} (gi·ªØ l·∫°i {len(vilqa_processed)/len(ds['train'])*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìä Th·ªëng k√™ sau x·ª≠ l√Ω:\")\n",
    "print(f\"- T·ªïng s·ªë m·∫´u ch·∫•t l∆∞·ª£ng: {len(vilqa_processed)}\")\n",
    "\n",
    "# Ph√¢n t√≠ch l·∫°i sau khi x·ª≠ l√Ω\n",
    "if vilqa_processed:\n",
    "    processed_q_lengths = [len(item['question']) for item in vilqa_processed]\n",
    "    processed_a_lengths = [len(item['answer']) for item in vilqa_processed]\n",
    "    \n",
    "    print(f\"\\nüî∏ ƒê·ªô d√†i c√¢u h·ªèi sau x·ª≠ l√Ω:\")\n",
    "    print(f\"   - Trung b√¨nh: {np.mean(processed_q_lengths):.1f} k√Ω t·ª±\")\n",
    "    print(f\"   - Min: {min(processed_q_lengths)}, Max: {max(processed_q_lengths)}\")\n",
    "    \n",
    "    print(f\"üî∏ ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi sau x·ª≠ l√Ω:\")\n",
    "    print(f\"   - Trung b√¨nh: {np.mean(processed_a_lengths):.1f} k√Ω t·ª±\")\n",
    "    print(f\"   - Min: {min(processed_a_lengths)}, Max: {max(processed_a_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2452031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ S·ª≠ d·ª•ng th∆∞ m·ª•c: ../data/finetune_data2\n",
      "üíæ ƒêang l∆∞u d·ªØ li·ªáu ViLQA...\n",
      "‚úÖ ƒê√£ l∆∞u ViLQA QA format: ../data/finetune_data2\\vilqa_qa_format.jsonl\n",
      "‚úÖ ƒê√£ l∆∞u ViLQA QA format: ../data/finetune_data2\\vilqa_qa_format.jsonl\n",
      "‚úÖ ƒê√£ l∆∞u ViLQA instruction format: ../data/finetune_data2\\vilqa_instruction_format.jsonl\n",
      "‚úÖ ƒê√£ l∆∞u ViLQA instruction format: ../data/finetune_data2\\vilqa_instruction_format.jsonl\n",
      "‚úÖ ƒê√£ l∆∞u ViLQA conversation format: ../data/finetune_data2\\vilqa_conversation_format.jsonl\n",
      "\n",
      "üìä T·ªïng k·∫øt:\n",
      "- T·ªïng s·ªë m·∫´u training: 43420\n",
      "- Format: QA, Instruction, Conversation\n",
      "‚úÖ ƒê√£ l∆∞u ViLQA conversation format: ../data/finetune_data2\\vilqa_conversation_format.jsonl\n",
      "\n",
      "üìä T·ªïng k·∫øt:\n",
      "- T·ªïng s·ªë m·∫´u training: 43420\n",
      "- Format: QA, Instruction, Conversation\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o th∆∞ m·ª•c v√† l∆∞u d·ªØ li·ªáu ViLQA\n",
    "import os\n",
    "import json\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c data/finetune_data cho ViLQA\n",
    "output_dir = \"../data/finetune_data2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ S·ª≠ d·ª•ng th∆∞ m·ª•c: {output_dir}\")\n",
    "\n",
    "# L∆∞u d·ªØ li·ªáu d∆∞·ªõi nhi·ªÅu format kh√°c nhau\n",
    "def save_jsonl(data, filepath):\n",
    "    \"\"\"L∆∞u d·ªØ li·ªáu d∆∞·ªõi ƒë·ªãnh d·∫°ng JSONL\"\"\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "def save_instruction_format(data, filepath):\n",
    "    \"\"\"L∆∞u d·ªØ li·ªáu d∆∞·ªõi ƒë·ªãnh d·∫°ng instruction tuning\"\"\"\n",
    "    instruction_data = []\n",
    "    for item in data:\n",
    "        instruction_item = {\n",
    "            \"instruction\": \"Tr·∫£ l·ªùi c√¢u h·ªèi ph√°p lu·∫≠t sau:\",\n",
    "            \"input\": item['question'],\n",
    "            \"output\": item['answer']\n",
    "        }\n",
    "        instruction_data.append(instruction_item)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for item in instruction_data:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "def save_conversation_format(data, filepath):\n",
    "    \"\"\"L∆∞u d·ªØ li·ªáu d∆∞·ªõi ƒë·ªãnh d·∫°ng conversation\"\"\"\n",
    "    conversation_data = []\n",
    "    for item in data:\n",
    "        conversation_item = {\n",
    "            \"conversations\": [\n",
    "                {\"role\": \"user\", \"content\": item['question']},\n",
    "                {\"role\": \"assistant\", \"content\": item['answer']}\n",
    "            ]\n",
    "        }\n",
    "        conversation_data.append(conversation_item)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for item in conversation_data:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "print(\"üíæ ƒêang l∆∞u d·ªØ li·ªáu ViLQA...\")\n",
    "\n",
    "# L∆∞u QA format\n",
    "vilqa_qa_path = os.path.join(output_dir, \"vilqa_qa_format.jsonl\")\n",
    "save_jsonl(vilqa_processed, vilqa_qa_path)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u ViLQA QA format: {vilqa_qa_path}\")\n",
    "\n",
    "# L∆∞u instruction format\n",
    "vilqa_instruction_path = os.path.join(output_dir, \"vilqa_instruction_format.jsonl\")\n",
    "save_instruction_format(vilqa_processed, vilqa_instruction_path)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u ViLQA instruction format: {vilqa_instruction_path}\")\n",
    "\n",
    "# L∆∞u conversation format\n",
    "vilqa_conversation_path = os.path.join(output_dir, \"vilqa_conversation_format.jsonl\")\n",
    "save_conversation_format(vilqa_processed, vilqa_conversation_path)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u ViLQA conversation format: {vilqa_conversation_path}\")\n",
    "\n",
    "print(f\"\\nüìä T·ªïng k·∫øt:\")\n",
    "print(f\"- T·ªïng s·ªë m·∫´u training: {len(vilqa_processed)}\")\n",
    "print(f\"- Format: QA, Instruction, Conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd40e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u ViLQA metadata: ../data/finetune_data2\\vilqa_metadata.json\n",
      "\n",
      "üìù M·∫´u d·ªØ li·ªáu ViLQA c√°c format:\n",
      "\n",
      "üî∏ QA Format:\n",
      "Question: Th·ª±c hi·ªán c·∫Øt gi·∫£m h·ªì s∆° thay ƒë·ªïi m·ª©c v·ªën ƒëi·ªÅu l·ªá c·ªßa ng√¢n h√†ng h·ª£p t√°c x√£ trong qu√Ω 2 nƒÉm 2024?...\n",
      "Answer: CƒÉn c·ª© M·ª•c 3 Ph·∫ßn 3 Ph∆∞∆°ng √°n c·∫Øt gi·∫£m, ƒë∆°n gi·∫£n h√≥a quy ƒë·ªãnh li√™n quan ƒë·∫øn ho·∫°t ƒë·ªông kinh doanh thu...\n",
      "\n",
      "üî∏ Instruction Format:\n",
      "Instruction: Tr·∫£ l·ªùi c√¢u h·ªèi ph√°p lu·∫≠t sau:\n",
      "Input: Th·ª±c hi·ªán c·∫Øt gi·∫£m h·ªì s∆° thay ƒë·ªïi m·ª©c v·ªën ƒëi·ªÅu l·ªá c·ªßa ng√¢n h√†ng h·ª£p t√°c x√£ trong qu√Ω 2 nƒÉm 2024?...\n",
      "Output: CƒÉn c·ª© M·ª•c 3 Ph·∫ßn 3 Ph∆∞∆°ng √°n c·∫Øt gi·∫£m, ƒë∆°n gi·∫£n h√≥a quy ƒë·ªãnh li√™n quan ƒë·∫øn ho·∫°t ƒë·ªông kinh doanh thu...\n",
      "\n",
      "üî∏ Conversation Format:\n",
      "User: Th·ª±c hi·ªán c·∫Øt gi·∫£m h·ªì s∆° thay ƒë·ªïi m·ª©c v·ªën ƒëi·ªÅu l·ªá c·ªßa ng√¢n h√†ng h·ª£p t√°c x√£ trong qu√Ω 2 nƒÉm 2024?...\n",
      "Assistant: CƒÉn c·ª© M·ª•c 3 Ph·∫ßn 3 Ph∆∞∆°ng √°n c·∫Øt gi·∫£m, ƒë∆°n gi·∫£n h√≥a quy ƒë·ªãnh li√™n quan ƒë·∫øn ho·∫°t ƒë·ªông kinh doanh thu...\n",
      "\n",
      "üéâ Ho√†n th√†nh x·ª≠ l√Ω ViLQA! ƒê√£ l∆∞u 43420 m·∫´u d·ªØ li·ªáu training v√†o ../data/finetune_data2\n",
      "\n",
      "üìÅ Files ViLQA ƒë√£ t·∫°o:\n",
      "   - vilqa_qa_format.jsonl: 54.15 MB\n",
      "   - vilqa_instruction_format.jsonl: 56.47 MB\n",
      "   - vilqa_conversation_format.jsonl: 56.63 MB\n",
      "   - vilqa_metadata.json: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o metadata cho ViLQA dataset\n",
    "vilqa_metadata = {\n",
    "    \"dataset_info\": {\n",
    "        \"source\": \"huyhuy123/ViLQA\",\n",
    "        \"description\": \"Vietnamese Legal Q&A Dataset (ViLQA) processed for fine-tuning\",\n",
    "        \"total_samples\": len(vilqa_processed),\n",
    "        \"training_samples\": len(vilqa_processed),\n",
    "        \"split_type\": \"training_only\"\n",
    "    },\n",
    "    \"processing_info\": {\n",
    "        \"filters_applied\": [\n",
    "            \"Minimum question length: 10 characters\",\n",
    "            \"Minimum answer length: 50 characters\", \n",
    "            \"Maximum answer length: 8000 characters\",\n",
    "            \"Text cleaning: removed extra whitespace and special characters\"\n",
    "        ],\n",
    "        \"retention_rate\": f\"{len(vilqa_processed)/len(ds['train'])*100:.1f}%\",\n",
    "        \"original_samples\": len(ds['train']),\n",
    "        \"processed_samples\": len(vilqa_processed)\n",
    "    },\n",
    "    \"file_formats\": {\n",
    "        \"qa_format\": \"Simple question-answer pairs for training\",\n",
    "        \"instruction_format\": \"Instruction tuning format with instruction/input/output\",\n",
    "        \"conversation_format\": \"Multi-turn conversation format for chatbot training\"\n",
    "    },\n",
    "    \"statistics\": {\n",
    "        \"avg_question_length\": np.mean([len(item['question']) for item in vilqa_processed]),\n",
    "        \"avg_answer_length\": np.mean([len(item['answer']) for item in vilqa_processed])\n",
    "    }\n",
    "}\n",
    "\n",
    "# L∆∞u metadata cho ViLQA\n",
    "vilqa_metadata_path = os.path.join(output_dir, \"vilqa_metadata.json\")\n",
    "with open(vilqa_metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(vilqa_metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u ViLQA metadata: {vilqa_metadata_path}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu t·ª´ c√°c format\n",
    "print(\"\\nüìù M·∫´u d·ªØ li·ªáu ViLQA c√°c format:\")\n",
    "\n",
    "print(\"\\nüî∏ QA Format:\")\n",
    "sample_qa = vilqa_processed[0]\n",
    "print(f\"Question: {sample_qa['question'][:100]}...\")\n",
    "print(f\"Answer: {sample_qa['answer'][:100]}...\")\n",
    "\n",
    "print(\"\\nüî∏ Instruction Format:\")\n",
    "print(f\"Instruction: Tr·∫£ l·ªùi c√¢u h·ªèi ph√°p lu·∫≠t sau:\")\n",
    "print(f\"Input: {sample_qa['question'][:100]}...\")\n",
    "print(f\"Output: {sample_qa['answer'][:100]}...\")\n",
    "\n",
    "print(\"\\nüî∏ Conversation Format:\")\n",
    "print(f\"User: {sample_qa['question'][:100]}...\")\n",
    "print(f\"Assistant: {sample_qa['answer'][:100]}...\")\n",
    "\n",
    "print(f\"\\nüéâ Ho√†n th√†nh x·ª≠ l√Ω ViLQA! ƒê√£ l∆∞u {len(vilqa_processed)} m·∫´u d·ªØ li·ªáu training v√†o {output_dir}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã th·ªëng k√™ file\n",
    "print(f\"\\nüìÅ Files ViLQA ƒë√£ t·∫°o:\")\n",
    "vilqa_files = [\"vilqa_qa_format.jsonl\", \"vilqa_instruction_format.jsonl\", \"vilqa_conversation_format.jsonl\", \"vilqa_metadata.json\"]\n",
    "for filename in vilqa_files:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"   - {filename}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate d·ªØ li·ªáu ViLQA ƒë√£ l∆∞u\n",
    "def validate_jsonl_file(filepath, expected_count, dataset_name=\"\"):\n",
    "    \"\"\"Ki·ªÉm tra t√≠nh to√†n v·∫πn c·ªßa file JSONL\"\"\"\n",
    "    try:\n",
    "        count = 0\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                json.loads(line.strip())  # Ki·ªÉm tra JSON h·ª£p l·ªá\n",
    "                count += 1\n",
    "        \n",
    "        if count == expected_count:\n",
    "            print(f\"‚úÖ {os.path.basename(filepath)}: {count} d√≤ng (OK)\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå {os.path.basename(filepath)}: {count} d√≤ng (Expected: {expected_count})\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error validating {os.path.basename(filepath)}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"üîç Ki·ªÉm tra t√≠nh to√†n v·∫πn d·ªØ li·ªáu ViLQA:\")\n",
    "\n",
    "vilqa_files_to_check = [\n",
    "    \"vilqa_qa_format.jsonl\",\n",
    "    \"vilqa_instruction_format.jsonl\", \n",
    "    \"vilqa_conversation_format.jsonl\"\n",
    "]\n",
    "\n",
    "all_valid = True\n",
    "\n",
    "print(\"\\nüìÇ ViLQA files:\")\n",
    "for filename in vilqa_files_to_check:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if not validate_jsonl_file(filepath, len(vilqa_processed), \"ViLQA\"):\n",
    "        all_valid = False\n",
    "\n",
    "# Ki·ªÉm tra metadata\n",
    "vilqa_metadata_file = os.path.join(output_dir, \"vilqa_metadata.json\")\n",
    "try:\n",
    "    with open(vilqa_metadata_file, 'r', encoding='utf-8') as f:\n",
    "        metadata_loaded = json.load(f)\n",
    "    print(f\"‚úÖ vilqa_metadata.json: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå vilqa_metadata.json: Error - {e}\")\n",
    "    all_valid = False\n",
    "\n",
    "if all_valid:\n",
    "    print(f\"\\nüéâ T·∫•t c·∫£ files ViLQA ƒë·ªÅu h·ª£p l·ªá! Dataset ƒë√£ s·∫µn s√†ng ƒë·ªÉ training.\")\n",
    "    print(f\"\\nüí° S·ª≠ d·ª•ng cho training:\")\n",
    "    print(f\"   - vilqa_qa_format.jsonl: Cho traditional Q&A training\")\n",
    "    print(f\"   - vilqa_instruction_format.jsonl: Cho instruction-following models\") \n",
    "    print(f\"   - vilqa_conversation_format.jsonl: Cho chatbot training\")\n",
    "    print(f\"   - T·ªïng {len(vilqa_processed)} m·∫´u training data\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è C√≥ l·ªói x·∫£y ra v·ªõi files ViLQA. Vui l√≤ng ki·ªÉm tra l·∫°i.\")\n",
    "\n",
    "print(f\"\\nüìç ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu ViLQA: {os.path.abspath(output_dir)}\")\n",
    "\n",
    "# T·ªïng k·∫øt final\n",
    "print(f\"\\nüìã T·ªïng k·∫øt dataset ViLQA:\")\n",
    "print(f\"   - Ngu·ªìn: huyhuy123/ViLQA\")\n",
    "print(f\"   - S·ªë m·∫´u g·ªëc: {len(ds['train'])}\")\n",
    "print(f\"   - S·ªë m·∫´u sau x·ª≠ l√Ω: {len(vilqa_processed)}\")\n",
    "print(f\"   - T·ª∑ l·ªá gi·ªØ l·∫°i: {len(vilqa_processed)/len(ds['train'])*100:.1f}%\")\n",
    "print(f\"   - M·ª•c ƒë√≠ch: Training chatbot ph√°p lu·∫≠t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
