# Vietnamese Legal Chatbot RAG System

A comprehensive RAG (Retrieval-Augmented Generation) system for Vietnamese legal document question-answering, built with modern AI technologies and microservices architecture.

## ğŸ›ï¸ Overview

This system provides intelligent legal consultation services for Vietnamese users by combining:
- **Large Language Models** for natural language understanding and generation
- **Vector Database** for semantic document retrieval
- **Legal Document Processing Pipeline** for data preparation
- **Web-based Chat Interface** for user interaction
- **Scalable Backend Architecture** with microservices

## ğŸš€ Features

### Core Capabilities
- **Vietnamese Legal Q&A**: Answers legal questions based on Vietnamese law documents
- **Document Retrieval**: Semantic search through legal corpus using vector embeddings
- **Context-Aware Responses**: Provides accurate answers with source document references
- **Real-time Chat Interface**: User-friendly web interface for legal consultations
- **Multi-format Support**: Processes various document formats (PDF, CSV, JSON, JSONL)

### Technical Features
- **RAG Architecture**: Combines retrieval and generation for accurate responses
- **Vector Search**: ChromaDB for efficient semantic document retrieval
- **LLM Integration**: Support for multiple language models (OpenAI GPT, LLaMA)
- **Scalable Processing**: Apache Spark for large-scale document processing
- **Microservices**: Dockerized components with Redis queue management
- **Data Pipeline**: Automated ETL for legal document ingestion

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚  Data Pipeline  â”‚
â”‚   (Streamlit)   â”‚â”€â”€â”€â–¶â”‚   (FastAPI)     â”‚â”€â”€â”€â–¶â”‚   (Spark)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                         â”‚
                              â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector DB      â”‚    â”‚    Redis        â”‚    â”‚   PostgreSQL    â”‚
â”‚  (ChromaDB)     â”‚    â”‚   (Queue)       â”‚    â”‚  (Metadata)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Vietnamese-Legal-Chatbot-RAG-System/
â”œâ”€â”€ backend/                    # FastAPI backend service
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.py             # Main FastAPI application
â”‚   â”‚   â”œâ”€â”€ brain.py           # LLM integration and chat logic
â”‚   â”‚   â”œâ”€â”€ vectorize.py       # Vector database operations
â”‚   â”‚   â”œâ”€â”€ database.py        # Database connections
â”‚   â”‚   â”œâ”€â”€ models.py          # Data models
â”‚   â”‚   â”œâ”€â”€ tasks.py           # Celery background tasks
â”‚   â”‚   â”œâ”€â”€ cache.py           # Caching utilities
â”‚   â”‚   â”œâ”€â”€ configs.py         # Configuration management
â”‚   â”‚   â”œâ”€â”€ splitter.py        # Document text splitting
â”‚   â”‚   â”œâ”€â”€ summarizer.py      # Text summarization
â”‚   â”‚   â””â”€â”€ utils.py           # Utility functions
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile            # Container configuration
â”‚   â”œâ”€â”€ docker-compose.yml    # Backend services
â”‚   â”œâ”€â”€ entrypoint.sh         # Container startup script
â”‚   â””â”€â”€ README.md             # Backend documentation
â”œâ”€â”€ frontend/                  # Streamlit web interface
â”‚   â”œâ”€â”€ chat_interface.py     # Main chat application
â”‚   â”œâ”€â”€ config.toml          # Streamlit configuration
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile           # Container configuration
â”‚   â”œâ”€â”€ docker-compose.yml   # Frontend services
â”‚   â””â”€â”€ entrypoint.sh        # Container startup script
â”œâ”€â”€ data_pipeline/            # Data processing pipeline
â”‚   â”œâ”€â”€ utils/               # Processing utilities
â”‚   â”œâ”€â”€ data/                # Raw and processed data
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ README.md            # Pipeline documentation (detailed)
â”œâ”€â”€ database/                 # Database setup
â”‚   â”œâ”€â”€ init.sql             # Initial database schema
â”‚   â”œâ”€â”€ docker-compose.yml   # Database services
â”‚   â”œâ”€â”€ .env                 # Database environment
â”‚   â””â”€â”€ README.md            # Database documentation
â”œâ”€â”€ test/                     # Test suite
â”‚   â””â”€â”€ test_smoke.py        # Smoke tests
â”œâ”€â”€ requirements_dev.txt      # Development dependencies
â””â”€â”€ LICENSE                   # Project license
```

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI**: High-performance API framework
- **Celery**: Distributed task queue for background processing
- **Redis**: Message broker and caching
- **PostgreSQL**: Metadata and conversation storage
- **ChromaDB**: Vector database for document embeddings

### Data Processing
- **Apache Spark**: Large-scale data processing
- **Pandas**: Data manipulation and analysis
- **Transformers**: Text embedding generation
- **OpenAI API**: GPT model integration

### Frontend
- **Streamlit**: Interactive web application framework
- **Python**: Core programming language

### Infrastructure
- **Docker**: Containerization
- **Docker Compose**: Multi-container orchestration
- **AWS S3**: Cloud storage (optional)

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Python 3.8+
- 8GB+ RAM recommended
- AWS credentials (for S3 integration, optional)

### 1. Clone Repository
```bash
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System
```

### 2. Environment Setup
```bash
# Copy environment templates
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env

# Edit configurations as needed
nano backend/.env
nano frontend/.env
```

### 3. Start Services
```bash
# Start database services first
cd database && docker-compose up -d

# Start backend services
cd ../backend && docker-compose up -d

# Start frontend application
cd ../frontend && docker-compose up -d

# Alternative: Start individual services manually
cd backend && python src/app.py
cd frontend && streamlit run chat_interface.py
```

### 4. Access Application
- **Web Interface**: http://localhost:8501
- **API Documentation**: http://localhost:8000/docs
- **Database Admin**: http://localhost:5432

## ğŸ“Š Data Pipeline

### Processing Legal Documents

1. **Raw Data Preparation**
```bash
cd data_pipeline

# Place your legal documents in data/raw/rag_corpus/
# Supported formats: CSV, JSON, JSONL
```

2. **Run Processing Pipeline**

For detailed data processing instructions, see the comprehensive guide in:
ğŸ“– **[Data Pipeline Documentation](data_pipeline/README.md)**

The data pipeline supports:
- RAG corpus processing with Apache Spark
- Fine-tuning data preparation
- Document cleaning and validation
- S3 cloud storage integration

## ğŸ”§ Configuration

### Backend Configuration
```bash
# backend/.env
OPENAI_API_KEY=your_openai_api_key
CHROMA_HOST=localhost
CHROMA_PORT=8000
REDIS_URL=redis://localhost:6379
DATABASE_URL=postgresql://user:pass@localhost:5432/legal_chatbot
```

### Frontend Configuration
```bash
# frontend/.env
BACKEND_URL=http://localhost:8000
STREAMLIT_SERVER_PORT=8501
```

## ğŸ§ª Testing

```bash
# Run smoke tests
python test/test_smoke.py

# Test individual components
cd backend && python -m pytest tests/
cd frontend && python -m pytest tests/
```

## ğŸ“ˆ Performance & Scaling

### Expected Performance
- **Document Processing**: ~1.9M documents processed in ~30 minutes
- **Vector Search**: Sub-second response for semantic queries
- **Chat Response**: 2-5 seconds for complete RAG pipeline
- **Concurrent Users**: 50+ simultaneous chat sessions

### Scaling Options
- **Horizontal Scaling**: Multiple backend replicas with load balancer
- **Vector DB Scaling**: ChromaDB cluster or Pinecone cloud
- **Data Processing**: Spark cluster for large document volumes
- **Caching**: Redis for frequent queries and embeddings

## ğŸ¤– Model Integration

### Supported Models
- **OpenAI GPT-3.5/4**: Production-ready commercial API
- **LLaMA 2/3**: Open-source alternative for self-hosting
- **Vietnamese-specific models**: Fine-tuned on legal corpus

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Vietnamese legal document sources
- Open-source AI/ML community
- Contributors and beta testers

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System/issues)
- **Discussions**: [GitHub Discussions](https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System/discussions)
- **Email**: [mikeethanh@example.com](mailto:mikeethanh@example.com)

---

**Note**: This system is designed for educational and research purposes. Legal advice should always be verified with qualified legal professionals.