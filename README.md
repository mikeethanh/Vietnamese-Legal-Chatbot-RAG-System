# Vietnamese Legal Chatbot RAG System ğŸ›ï¸

A comprehensive Vietnamese legal consultation chatbot system built with RAG (Retrieval-Augmented Generation) technology, modern microservices architecture, and advanced AI technologies for intelligent legal document retrieval and consultation services.

## Table of Contents

- [I. Overview](#i-overview)
- [II. System Architecture](#ii-system-architecture)
- [III. Project Structure](#iii-project-structure)
- [IV. Technology Stack](#iv-technology-stack)
- [V. Quick Start Guide](#v-quick-start-guide)
- [VI. Data Pipeline Setup](#vi-data-pipeline-setup)
- [VII. Advanced Configuration](#vii-advanced-configuration)
- [VIII. Production Deployment](#viii-production-deployment)
- [IX. Testing and Quality Assurance](#ix-testing-and-quality-assurance)
- [X. Development Guide](#x-development-guide)
- [XI. Performance Monitoring](#xi-performance-monitoring)
- [XII. Troubleshooting](#xii-troubleshooting)
- [XIII. Documentation & Resources](#xiii-documentation--resources)

## I. Overview

Retrieval-augmented generation (RAG) systems combine generative AI with information retrieval to provide contextualized legal consultation services. This project deploys a comprehensive Vietnamese legal chatbot system using modern microservices architecture and advanced AI technologies.


## II. System Architecture

![System Architecture](asset/architecture_template.drawio.svg)


**(Video demonstration of system overview will be provided)**
## III. Project Structure

```
Vietnamese-Legal-Chatbot-RAG-System/
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ backend/                    # Backend API service (FastAPI)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.py                # Main FastAPI application
â”‚   â”‚   â”œâ”€â”€ agent.py              # AI agent with tool calling
â”‚   â”‚   â”œâ”€â”€ brain.py              # LLM integration and chat logic
â”‚   â”‚   â”œâ”€â”€ custom_embedding.py   # Custom embedding models
â”‚   â”‚   â”œâ”€â”€ legal_tools.py        # Legal-specific tools
â”‚   â”‚   â”œâ”€â”€ models.py             # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ query_rewriter.py     # Query optimization
â”‚   â”‚   â”œâ”€â”€ rerank.py             # Result re-ranking
â”‚   â”‚   â”œâ”€â”€ search.py             # Search functionality
â”‚   â”‚   â”œâ”€â”€ splitter.py           # Document text splitting
â”‚   â”‚   â”œâ”€â”€ summarizer.py         # Text summarization
â”‚   â”‚   â”œâ”€â”€ tasks.py              # Celery background tasks
â”‚   â”‚   â”œâ”€â”€ tavily_tool.py        # Web search integration
â”‚   â”‚   â””â”€â”€ vectorize.py          # Vector database operations
â”‚   â”œâ”€â”€ docker-compose.yml       # Backend services
â”‚   â”œâ”€â”€ Dockerfile               # Container configuration
â”‚   â”œâ”€â”€ entrypoint.sh           # Container startup script
â”‚   â”œâ”€â”€ import_data.sh          # Data import script
â”‚   â”œâ”€â”€ migration_title_to_question.sql # Database migration
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â””â”€â”€ ğŸ“š README.md            # Backend documentation
â”‚
â”œâ”€â”€ ğŸŒ frontend/                   # Web interface (Streamlit)
â”‚   â”œâ”€â”€ chat_interface.py        # Main chat application
â”‚   â”œâ”€â”€ config.toml             # Streamlit configuration
â”‚   â”œâ”€â”€ docker-compose.yml      # Frontend services
â”‚   â”œâ”€â”€ Dockerfile              # Container configuration
â”‚   â”œâ”€â”€ entrypoint.sh           # Container startup script
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”‚
â”œâ”€â”€ ğŸ”„ data_pipeline/             # Data processing pipeline
â”‚   â”œâ”€â”€ utils/                  # Processing utilities
â”‚   â”‚   â”œâ”€â”€ download_embed_data.ipynb      # Download legal corpus
â”‚   â”‚   â”œâ”€â”€ merge_instruction_data.py      # Merge instruction datasets
â”‚   â”‚   â”œâ”€â”€ process_finetune_data.ipynb    # Process training data
â”‚   â”‚   â”œâ”€â”€ process_finetune_data_2.ipynb  # ViLQA dataset processing
â”‚   â”‚   â””â”€â”€ process_finetune_data_3.ipynb  # Extended dataset processing
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ ğŸ“š README.md           # Pipeline documentation
â”‚
â”œâ”€â”€ ğŸ¤– llm_finetuning_serving/    # LLM fine-tuning and serving
â”‚   â”œâ”€â”€ data_processing/        # Data processing for LLM
â”‚   â”‚   â”œâ”€â”€ process_llama_data.py # Process LLaMA data
â”‚   â”‚   â”œâ”€â”€ processed_llama_data.jsonl # Processed data
â”‚   â”‚   â”œâ”€â”€ sample_processed_data.json # Sample data
â”‚   â”‚   â””â”€â”€ split_data.py       # Split datasets
â”‚   â”œâ”€â”€ docker/                 # Docker configurations
â”‚   â”‚   â””â”€â”€ docker-compose.yml  # LLM serving containers
â”‚   â”œâ”€â”€ evaluation/             # Model evaluation
â”‚   â”‚   â””â”€â”€ evaluate_model.py   # Evaluation scripts
â”‚   â”œâ”€â”€ finetune/               # Fine-tuning scripts
â”‚   â”‚   â””â”€â”€ train_llama.py      # LLaMA training
â”‚   â”œâ”€â”€ serving/                # Model serving
â”‚   â”‚   â””â”€â”€ serve_model.py      # Model serving script
â”‚   â”œâ”€â”€ do_spaces_manager.py    # DigitalOcean Spaces manager
â”‚   â”œâ”€â”€ prepare_data.sh         # Data preparation script
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ ğŸ“š README.md           # LLM documentation
â”‚
â”œâ”€â”€ ğŸ—„ï¸ database/                  # Database setup
â”‚   â”œâ”€â”€ docker-compose.yml     # Database services
â”‚   â”œâ”€â”€ init.sql               # Initial database schema
â”‚
â”œâ”€â”€ ğŸš€ embed_serving/             # Model serving and deployment
â”‚   â”œâ”€â”€ docker-compose.serving.yml  # Production deployment
â”‚   â”œâ”€â”€ Dockerfile.cpu-serving      # CPU serving container
â”‚   â”œâ”€â”€ requirements_serving.txt   # Serving dependencies
â”‚   â””â”€â”€ scripts/                   # Serving scripts
â”‚       â”œâ”€â”€ download_model_from_spaces.py  # Model download utility
â”‚       â””â”€â”€ serve_model.py         # Model serving script
â”‚   â””â”€â”€ ğŸ“š GPU_CPU_DEPLOYMENT_GUIDE.md  # Deployment guide
â”‚
â”œâ”€â”€ ğŸ§ª tests/                     # Test suite
â”‚   â”œâ”€â”€ __init__.py             # Test package init
â”‚   â”œâ”€â”€ conftest.py             # Pytest configuration
â”‚   â”œâ”€â”€ test_api_simple.py      # Simple API tests
â”‚   â”œâ”€â”€ test_backend_utils.py   # Backend utility tests
â”‚   â”œâ”€â”€ test_basic.py           # Basic functionality tests
â”‚   â””â”€â”€ ğŸ“š TESTING_SUMMARY.md   # Testing documentation
â”‚
â”œâ”€â”€ ğŸ“ docs/                      # Documentation
â”‚   â””â”€â”€ architecture_drawio_template.md # Architecture template
â”‚   â””â”€â”€ architecture_template.drawio    # Draw.io architecture file
â”‚   â””â”€â”€ ğŸ“š TESTING.md           # Testing documentation
â”‚
â”œâ”€â”€ .github/                     # GitHub workflows and templates
â”œâ”€â”€ Makefile                     # Build automation
â”œâ”€â”€ mypy.ini                     # MyPy configuration
â”œâ”€â”€ .pre-commit-config.yaml      # Pre-commit hooks
â”œâ”€â”€ pyproject.toml               # Python project configuration
â”œâ”€â”€ pytest.ini                  # Pytest configuration
â”œâ”€â”€ requirements_dev.txt         # Development dependencies
â”œâ”€â”€ setup.cfg                    # Setup configuration
â””â”€â”€ ğŸ“š README.md                # This documentation
```

## IV. Technology Stack

### ğŸ–¥ï¸ Backend
- **FastAPI**: High-performance API framework with async support
- **Celery**: Distributed queue for background task processing
- **Redis**: Message broker and caching layer
- **MySQL/PostgreSQL**: Metadata and conversation history storage
- **QdrantDB**: Vector database for document embeddings
- **Pydantic**: Data validation and serialization
- **SQLAlchemy**: Database ORM

### ğŸ”„ Data Processing
- **LlamaIndex**: Document indexing and retrieval framework
- **Pandas**: Data manipulation and analysis
- **Sentence Transformers**: Specialized embedding models

### ğŸ¤– AI/ML
- **OpenAI API**: GPT-3.5/4 for production
- **LLaMA**: Open-source alternative for fine-tuning
- **BGE-M3**: Multilingual embedding model
- **Cohere**: Additional AI model support
- **BM25**: Traditional text retrieval

### ğŸŒ Frontend
- **Streamlit**: Interactive web application framework
- **Python**: Core programming language

### ğŸ—ï¸ Infrastructure
- **Docker**: Containerization
- **Docker Compose**: Multi-container orchestration
- **DigitalOcean**: Cloud hosting platform
- **DigitalOcean Spaces**: Object storage

### ğŸ” Search & Integration
- **Tavily**: Web search integration
- **Google API**: Additional search capabilities

## V. Quick Start Guide

### 1. Prerequisites

```bash
# System requirements
- Docker and Docker Compose v2.0+
- Python 3.8+ (for development)
- 8GB+ RAM (recommended 16GB)
- Ubuntu 20.04+ or macOS 10.15+

# Check requirements
docker --version
docker-compose --version
python3 --version
```

### 2. Clone and Setup

```bash
# Clone repository
git clone https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System.git
cd Vietnamese-Legal-Chatbot-RAG-System

# Create Docker network
docker network create legal-chatbot-network

# Copy environment templates
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env
cp database/.env.example database/.env
```

### 3. Environment Configuration

#### Backend Configuration
```bash
# Edit backend/.env
nano backend/.env

# Important variables:
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
DATABASE_URL=postgresql://legal_user:legal_pass@postgres:5432/legal_chatbot
REDIS_URL=redis://redis:6379/0
CHROMA_HOST=chromadb
CHROMA_PORT=8000
```

#### Database Configuration
```bash
# Edit database/.env
nano database/.env

# Database configuration:
POSTGRES_DB=legal_chatbot
POSTGRES_USER=legal_user
POSTGRES_PASSWORD=legal_pass
REDIS_PASSWORD=redis_secret_password
```

### 4. Service Deployment

**(Video tutorial for deployment process will be provided)**

```bash
# Start all services with Docker Compose
cd Vietnamese-Legal-Chatbot-RAG-System

# Build and start core services
docker-compose up -d --build

# Verify services are running
docker-compose ps
```

### 5. Data Import

#### Automatic sample data import
```bash
cd backend

# Import training data
docker exec -it chatbot-api python /usr/src/app/src/import_data.py \
  --data-file /usr/src/app/data/train_qa_format.jsonl \
  --collection llm \
  --batch-size 100

```

### 6. Access Applications

- **ğŸ–¥ï¸ Web Chat Interface**: http://localhost:8501
- **ğŸ“š API Documentation**: http://localhost:8000/docs
- **ğŸ“Š API Health Check**: http://localhost:8000/health
- **ğŸ—„ï¸ ChromaDB Dashboard**: http://localhost:8001
- **ğŸ’¾ Database Admin** (pgAdmin): http://localhost:5050

### 7. System Verification

**(Video demonstration of system verification will be provided)**

```bash
# Health checks
curl http://localhost:8000/health
curl http://localhost:8501/health

# Test chat API
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What does Vietnamese civil law say about property rights?",
    "conversation_id": "test-conversation-123"
  }'

# Check logs if there are errors
docker logs chatbot-api
docker logs chatbot-worker
docker logs streamlit-app
```

## VI. Data Pipeline Setup

**(Video tutorial for data pipeline setup will be provided)**

### 1. Legal Document Processing

Detailed data processing workflow is described in the [Data Pipeline Documentation](data_pipeline/README.md).

```bash
cd data_pipeline

# 1. Download Vietnamese legal corpus
jupyter notebook utils/download_embed_data.ipynb

# 2. Process fine-tuning data
jupyter notebook utils/process_finetune_data.ipynb

# 3. Validate data quality
python scripts/validate_data.py
```

### 2. Data Statistics
- **Legal Corpus**: 1.9M+ Vietnamese legal documents
- **Training Data**: 225K+ high-quality Q&A pairs  
- **Fine-tuning Sets**: 3 specialized datasets
- **Coverage**: Complete coverage of major legal domains


## VIII. Production Deployment

**(Video tutorial for production deployment will be provided)**

### 1. Cloud Deployment Guide

Detailed deployment instructions are available in:
ğŸ“– **[GPU CPU Deployment Guide](embed_serving/GPU_CPU_DEPLOYMENT_GUIDE.md)**

```bash
# Quick production deployment on Digital Ocean
cd embed_serving
docker-compose -f docker-compose.serving.yml up -d
```

### 2. Security Configuration

- [ ] API rate limiting enabled
- [ ] Database credentials encrypted  
- [ ] HTTPS/SSL certificates setup
- [ ] Firewall rules configured
- [ ] Regular security updates scheduled
- [ ] Backup strategy established


## X. Development Guide

### 4. Contributing Guidelines

1. **Fork repository** and create feature branch
2. **Implement changes** with tests and documentation  
3. **Run quality checks**: `./scripts/pre-commit.sh`
4. **Submit Pull Request** with detailed description
5. **Code review** and merge approval

## XIII. Documentation & Resources

### 1. Technical Documentation
- **[Backend API Documentation](backend/README.md)** - Detailed backend implementation
- **[Data Pipeline Guide](data_pipeline/README.md)** - Comprehensive data processing  
- **[Database Schema](database/README.md)** - Database design and migrations
- **[Deployment Guide](embed_serving/GPU_CPU_DEPLOYMENT_GUIDE.md)** - Production deployment
- **[API Usage Examples](embed_serving/API_USAGE.md)** - API usage patterns


## ğŸ“„ License

This project is distributed under **MIT License** - see the [LICENSE](LICENSE) file for details.

### ğŸ”’ Usage Terms
- âœ… Commercial use allowed
- âœ… Modification and distribution allowed
- âœ… Private use encouraged
- â— No warranty provided
- â— Legal advice disclaimer applies

---

## âš ï¸ Disclaimer

**Important Statement**: This system is designed for **research, educational, and reference support purposes**.

ğŸš¨ **Legal Notice**:
- AI results cannot replace consultation from qualified lawyers
- Always verify information with legal professionals before making decisions
- The system may have errors and does not guarantee 100% accuracy
- Do not use for important legal matters without professional consultation

---

<div align="center">

**â­ If this project is helpful, please star the repository to support the development team! â­**

Made with â¤ï¸ for Vietnamese Legal Community

[ğŸŒŸ Star](https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System/stargazers) â€¢ [ğŸ´ Fork](https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System/fork) â€¢ [ğŸ“š Docs](https://github.com/mikeethanh/Vietnamese-Legal-Chatbot-RAG-System/wiki) â€¢ [ğŸ’¬ Discord](https://discord.gg/legal-chatbot)

</div>
